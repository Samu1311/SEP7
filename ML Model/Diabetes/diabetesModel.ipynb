{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection - Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the Data Exploration phase is to understand the structure, quality, and distribution of the data, identifying potential issues such as missing values, zero counts, and imbalance in the target variable (diabetes). Below is the breakdown of the steps taken, their purpose, and the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Relevant Packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>58552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.885856</td>\n",
       "      <td>0.07485</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.320767</td>\n",
       "      <td>5.527507</td>\n",
       "      <td>138.058060</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.516840</td>\n",
       "      <td>0.26315</td>\n",
       "      <td>0.194593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.636783</td>\n",
       "      <td>1.070672</td>\n",
       "      <td>40.708136</td>\n",
       "      <td>0.278883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.630000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.580000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.690000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender            age  hypertension  heart_disease smoking_history  \\\n",
       "count   100000  100000.000000  100000.00000  100000.000000          100000   \n",
       "unique       3            NaN           NaN            NaN               6   \n",
       "top     Female            NaN           NaN            NaN         No Info   \n",
       "freq     58552            NaN           NaN            NaN           35816   \n",
       "mean       NaN      41.885856       0.07485       0.039420             NaN   \n",
       "std        NaN      22.516840       0.26315       0.194593             NaN   \n",
       "min        NaN       0.080000       0.00000       0.000000             NaN   \n",
       "25%        NaN      24.000000       0.00000       0.000000             NaN   \n",
       "50%        NaN      43.000000       0.00000       0.000000             NaN   \n",
       "75%        NaN      60.000000       0.00000       0.000000             NaN   \n",
       "max        NaN      80.000000       1.00000       1.000000             NaN   \n",
       "\n",
       "                  bmi    HbA1c_level  blood_glucose_level       diabetes  \n",
       "count   100000.000000  100000.000000        100000.000000  100000.000000  \n",
       "unique            NaN            NaN                  NaN            NaN  \n",
       "top               NaN            NaN                  NaN            NaN  \n",
       "freq              NaN            NaN                  NaN            NaN  \n",
       "mean        27.320767       5.527507           138.058060       0.085000  \n",
       "std          6.636783       1.070672            40.708136       0.278883  \n",
       "min         10.010000       3.500000            80.000000       0.000000  \n",
       "25%         23.630000       4.800000           100.000000       0.000000  \n",
       "50%         27.320000       5.800000           140.000000       0.000000  \n",
       "75%         29.580000       6.200000           159.000000       0.000000  \n",
       "max         95.690000       9.000000           300.000000       1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load the Diabetes dataset\n",
    "diabetes_no_balanced = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "print(f\"Dataset shape: {diabetes_no_balanced.shape}\")\n",
    "\n",
    "diabetes_no_balanced.describe(include='all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: Load the dataset into a pandas DataFrame and inspect its size and statistical properties.\n",
    "Results:Dataset shape: (100,000, 9) → 100,000 rows and 9 columns.\n",
    "Descriptive statistics showed:\n",
    "The diabetes column has a mean of 0.085, indicating a class imbalance (most samples are negative).\n",
    "Several categorical columns like gender and smoking_history were identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting Column Data Types and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                  object\n",
      "age                    float64\n",
      "hypertension             int64\n",
      "heart_disease            int64\n",
      "smoking_history         object\n",
      "bmi                    float64\n",
      "HbA1c_level            float64\n",
      "blood_glucose_level      int64\n",
      "diabetes                 int64\n",
      "dtype: object\n",
      "                     NaN Count  Zero Count\n",
      "gender                       0           0\n",
      "age                          0           0\n",
      "hypertension                 0       92515\n",
      "heart_disease                0       96058\n",
      "smoking_history              0           0\n",
      "bmi                          0           0\n",
      "HbA1c_level                  0           0\n",
      "blood_glucose_level          0           0\n",
      "diabetes                     0       91500\n"
     ]
    }
   ],
   "source": [
    "# Print the data types of all columns\n",
    "print(diabetes_no_balanced.dtypes)\n",
    "\n",
    "# Count the number of NaN values in each column\n",
    "nan_counts = diabetes_no_balanced.isna().sum()\n",
    "\n",
    "# Count the number of 0 values in each column\n",
    "zero_counts = (diabetes_no_balanced == 0).sum()\n",
    "\n",
    "# Combine the counts into a DataFrame for better readability\n",
    "counts = pd.DataFrame({'NaN Count': nan_counts, 'Zero Count': zero_counts})\n",
    "\n",
    "# Print the result\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Check data types to confirm which columns are numeric (int64, float64) or categorical (object).\n",
    "Count missing (NaN) values and zero entries in each column to identify potential data quality issues.\n",
    "Results:\n",
    "No missing (NaN) values in the dataset.\n",
    "Columns like hypertension, heart_disease, and diabetes had a significant number of zero values:\n",
    "hypertension: 92,515 zeros\n",
    "heart_disease: 96,058 zeros\n",
    "diabetes: 91,500 zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing Distribtuion\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "diabetes_no_balanced.hist(figsize=(10, 10), bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: Visualize the distribution of each numeric column to understand their range, central tendency, and skewness.\n",
    "Results:\n",
    "Age: Most entries are between 20 and 80, with a peak around 40–50.\n",
    "BMI: Skewed distribution with values clustered around 25–30.\n",
    "HbA1c_level: Peaks around 5–6, matching expected values for blood glucose levels.\n",
    "Blood Glucose Level: Multimodal distribution with clusters around 100, 150, and 200.\n",
    "Diabetes (target): Severe class imbalance, with far fewer positive cases (1) than negative (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning** is the process of preparing raw data for analysis by addressing issues such as duplicates, missing values, invalid entries, or outliers. This step ensures that the data is accurate, consistent, and relevant for machine learning models. After exploring the dataset, we decided to:\n",
    "1. Take a snapshot of **10,000 entries** from the original dataset (100,000 rows) to ensure manageable computational load and align the size with our second dataset, which has closer to 10,000 entries.\n",
    "2. Confirm that there were **no missing values** or **duplicates**.\n",
    "3. Retain **outliers** since they are part of real-world data and can provide valuable insights for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive cases: 5000\n",
      "Number of negative cases: 5000\n",
      "Total dataset size: 10000 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Separate positive and negative cases\n",
    "positive_cases = diabetes_no_balanced[diabetes_no_balanced['diabetes'] == 1]  # Assuming '1' indicates positive diabetes cases\n",
    "negative_cases = diabetes_no_balanced[diabetes_no_balanced['diabetes'] == 0]  # Assuming '0' indicates negative diabetes cases\n",
    "\n",
    "# 3. Take 5,000 rows from each category\n",
    "positive_subset = positive_cases.head(5000)\n",
    "negative_subset = negative_cases.head(5000)\n",
    "\n",
    "# 4. Combine the positive and negative subsets\n",
    "diabetes = pd.concat([positive_subset, negative_subset], axis=0)\n",
    "\n",
    "# 5. Shuffle the dataset to randomize the rows\n",
    "diabetes = diabetes.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 6. Print the number of positive and negative cases to confirm balance\n",
    "positive_count = diabetes['diabetes'].value_counts()[1]\n",
    "negative_count = diabetes['diabetes'].value_counts()[0]\n",
    "\n",
    "print(f\"Number of positive cases: {positive_count}\")\n",
    "print(f\"Number of negative cases: {negative_count}\")\n",
    "print(f\"Total dataset size: {diabetes.shape[0]} rows\")\n",
    "\n",
    "# 7. Optionally, save the new balanced dataset to a CSV file (optional)\n",
    "# balanced_diabetes.to_csv('balanced_diabetes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                  object\n",
      "age                    float64\n",
      "hypertension             int64\n",
      "heart_disease            int64\n",
      "smoking_history         object\n",
      "bmi                    float64\n",
      "HbA1c_level            float64\n",
      "blood_glucose_level      int64\n",
      "diabetes                 int64\n",
      "dtype: object\n",
      "                     NaN Count  Zero Count\n",
      "gender                       0           0\n",
      "age                          0           0\n",
      "hypertension                 0        8479\n",
      "heart_disease                0        9120\n",
      "smoking_history              0           0\n",
      "bmi                          0           0\n",
      "HbA1c_level                  0           0\n",
      "blood_glucose_level          0           0\n",
      "diabetes                     0        5000\n"
     ]
    }
   ],
   "source": [
    "diabetes.describe(include='all')\n",
    "\n",
    "# Print the data types of all columns\n",
    "print(diabetes.dtypes)\n",
    "\n",
    "# Count the number of NaN values in each column\n",
    "nan_counts = diabetes.isna().sum()\n",
    "\n",
    "# Count the number of 0 values in each column\n",
    "zero_counts = (diabetes == 0).sum()\n",
    "\n",
    "# Combine the counts into a DataFrame for better readability\n",
    "counts = pd.DataFrame({'NaN Count': nan_counts, 'Zero Count': zero_counts})\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import matplotlib.pyplot as plt\\n\\n# Generate individual horizontal boxplots for each column\\nfor column in diabetes.columns:\\n     plt.figure(figsize=(8, 6))\\n     plt.boxplot(diabetes[column], vert=False)\\n     plt.title(f'Horizontal Boxplot of {column}')\\n     plt.xlabel('Values')\\n     plt.grid(True)\\n     plt.show() \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate individual horizontal boxplots for each column\n",
    "for column in diabetes.columns:\n",
    "     plt.figure(figsize=(8, 6))\n",
    "     plt.boxplot(diabetes[column], vert=False)\n",
    "     plt.title(f'Horizontal Boxplot of {column}')\n",
    "     plt.xlabel('Values')\n",
    "     plt.grid(True)\n",
    "     plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "0    5534\n",
      "1    4466\n",
      "Name: count, dtype: int64\n",
      "smoking_history\n",
      "0    7619\n",
      "1    2381\n",
      "Name: count, dtype: int64\n",
      "gender                   int64\n",
      "age                    float64\n",
      "hypertension             int64\n",
      "heart_disease            int64\n",
      "smoking_history          int64\n",
      "bmi                    float64\n",
      "HbA1c_level            float64\n",
      "blood_glucose_level      int64\n",
      "diabetes                 int64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuele Biondi\\AppData\\Local\\Temp\\ipykernel_15020\\4118663383.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  diabetes['gender'] = diabetes['gender'].replace({'Female': 0, 'Male': 1})\n",
      "C:\\Users\\Samuele Biondi\\AppData\\Local\\Temp\\ipykernel_15020\\4118663383.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  diabetes['smoking_history'] = diabetes['smoking_history'].replace({'No Info': 0, 'never': 0, 'former': 1, 'ever': 0, 'current': 1, 'not current': 0})\n"
     ]
    }
   ],
   "source": [
    "# Coverting Categorical features into binary\n",
    "\n",
    "# 1. Convert 'Female' to 0 and 'Male' to 1\n",
    "diabetes['gender'] = diabetes['gender'].replace({'Female': 0, 'Male': 1})\n",
    "\n",
    "diabetes['gender'] = diabetes['gender'].astype(int)\n",
    "\n",
    "print(diabetes['gender'].value_counts())\n",
    "\n",
    "# 2. Converting Smoking History\n",
    "\n",
    "diabetes['smoking_history'] = diabetes['smoking_history'].replace({'No Info': 0, 'never': 0, 'former': 1, 'ever': 0, 'current': 1, 'not current': 0})\n",
    "\n",
    "diabetes['smoking_history'] = diabetes['smoking_history'].astype(int)\n",
    "\n",
    "print(diabetes['smoking_history'].value_counts())\n",
    "\n",
    "# Observing the results\n",
    "\n",
    "print(diabetes.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the correlation matrix for numeric columns\n",
    "correlation_matrix = diabetes.corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.446600</td>\n",
       "      <td>50.481624</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>29.489158</td>\n",
       "      <td>6.167770</td>\n",
       "      <td>163.523500</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497165</td>\n",
       "      <td>21.505493</td>\n",
       "      <td>0.359136</td>\n",
       "      <td>0.283309</td>\n",
       "      <td>0.425942</td>\n",
       "      <td>7.468935</td>\n",
       "      <td>1.278503</td>\n",
       "      <td>57.143059</td>\n",
       "      <td>0.500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.760000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.880000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.720000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender           age  hypertension  heart_disease  \\\n",
       "count  10000.000000  10000.000000  10000.000000   10000.000000   \n",
       "mean       0.446600     50.481624      0.152100       0.088000   \n",
       "std        0.497165     21.505493      0.359136       0.283309   \n",
       "min        0.000000      0.080000      0.000000       0.000000   \n",
       "25%        0.000000     36.000000      0.000000       0.000000   \n",
       "50%        0.000000     54.000000      0.000000       0.000000   \n",
       "75%        1.000000     67.000000      0.000000       0.000000   \n",
       "max        1.000000     80.000000      1.000000       1.000000   \n",
       "\n",
       "       smoking_history           bmi   HbA1c_level  blood_glucose_level  \\\n",
       "count     10000.000000  10000.000000  10000.000000         10000.000000   \n",
       "mean          0.238100     29.489158      6.167770           163.523500   \n",
       "std           0.425942      7.468935      1.278503            57.143059   \n",
       "min           0.000000     10.010000      3.500000            80.000000   \n",
       "25%           0.000000     25.760000      5.700000           130.000000   \n",
       "50%           0.000000     27.320000      6.100000           155.000000   \n",
       "75%           0.000000     32.880000      6.600000           200.000000   \n",
       "max           1.000000     88.720000      9.000000           300.000000   \n",
       "\n",
       "           diabetes  \n",
       "count  10000.000000  \n",
       "mean       0.500000  \n",
       "std        0.500025  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.500000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.to_csv('diabetes_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.001, batch_size=16, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7543 - loss: 0.4981 - val_accuracy: 0.8820 - val_loss: 0.2732\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2776 - val_accuracy: 0.8867 - val_loss: 0.2587\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.2769 - val_accuracy: 0.8787 - val_loss: 0.2592\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2538 - val_accuracy: 0.8887 - val_loss: 0.2568\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2612 - val_accuracy: 0.8867 - val_loss: 0.2573\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2610 - val_accuracy: 0.8840 - val_loss: 0.2559\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.2580 - val_accuracy: 0.8813 - val_loss: 0.2569\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2593 - val_accuracy: 0.8840 - val_loss: 0.2546\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2585 - val_accuracy: 0.8840 - val_loss: 0.2539\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.2549 - val_accuracy: 0.8820 - val_loss: 0.2545\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2460 - val_accuracy: 0.8827 - val_loss: 0.2531\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.2537 - val_accuracy: 0.8820 - val_loss: 0.2532\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2503 - val_accuracy: 0.8827 - val_loss: 0.2516\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2568 - val_accuracy: 0.8827 - val_loss: 0.2524\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.2423 - val_accuracy: 0.8833 - val_loss: 0.2504\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.2370 - val_accuracy: 0.8833 - val_loss: 0.2498\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.2503 - val_accuracy: 0.8813 - val_loss: 0.2496\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2373 - val_accuracy: 0.8860 - val_loss: 0.2491\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2427 - val_accuracy: 0.8853 - val_loss: 0.2469\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2391 - val_accuracy: 0.8833 - val_loss: 0.2455\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.2430 - val_accuracy: 0.8833 - val_loss: 0.2447\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2328 - val_accuracy: 0.8860 - val_loss: 0.2416\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.2296 - val_accuracy: 0.8920 - val_loss: 0.2390\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2317 - val_accuracy: 0.8840 - val_loss: 0.2387\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2323 - val_accuracy: 0.8933 - val_loss: 0.2354\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2256 - val_accuracy: 0.8927 - val_loss: 0.2329\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.2290 - val_accuracy: 0.8920 - val_loss: 0.2305\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2291 - val_accuracy: 0.8920 - val_loss: 0.2287\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2256 - val_accuracy: 0.8940 - val_loss: 0.2269\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2234 - val_accuracy: 0.8947 - val_loss: 0.2252\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.2148 - val_accuracy: 0.8967 - val_loss: 0.2228\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2203 - val_accuracy: 0.8933 - val_loss: 0.2221\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.2231 - val_accuracy: 0.8933 - val_loss: 0.2201\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2162 - val_accuracy: 0.8967 - val_loss: 0.2186\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9024 - loss: 0.2120 - val_accuracy: 0.8947 - val_loss: 0.2172\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2162 - val_accuracy: 0.8960 - val_loss: 0.2172\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2191 - val_accuracy: 0.8947 - val_loss: 0.2153\n",
      "Epoch 38/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2274 - val_accuracy: 0.8927 - val_loss: 0.2157\n",
      "Epoch 39/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2126 - val_accuracy: 0.8980 - val_loss: 0.2134\n",
      "Epoch 40/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2088 - val_accuracy: 0.8987 - val_loss: 0.2130\n",
      "Epoch 41/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.2162 - val_accuracy: 0.8973 - val_loss: 0.2113\n",
      "Epoch 42/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2038 - val_accuracy: 0.8987 - val_loss: 0.2110\n",
      "Epoch 43/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2106 - val_accuracy: 0.8967 - val_loss: 0.2110\n",
      "Epoch 44/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2157 - val_accuracy: 0.8993 - val_loss: 0.2103\n",
      "Epoch 45/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.2144 - val_accuracy: 0.8947 - val_loss: 0.2102\n",
      "Epoch 46/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2071 - val_accuracy: 0.8960 - val_loss: 0.2095\n",
      "Epoch 47/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2032 - val_accuracy: 0.8940 - val_loss: 0.2100\n",
      "Epoch 48/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9020 - loss: 0.2120 - val_accuracy: 0.8960 - val_loss: 0.2093\n",
      "Epoch 49/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.2070 - val_accuracy: 0.8960 - val_loss: 0.2083\n",
      "Epoch 50/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.1971 - val_accuracy: 0.8967 - val_loss: 0.2077\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.001, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.5397 - val_accuracy: 0.8767 - val_loss: 0.2784\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.3015 - val_accuracy: 0.8793 - val_loss: 0.2586\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.2754 - val_accuracy: 0.8800 - val_loss: 0.2575\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2639 - val_accuracy: 0.8853 - val_loss: 0.2550\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.2669 - val_accuracy: 0.8867 - val_loss: 0.2539\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.2538 - val_accuracy: 0.8827 - val_loss: 0.2526\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.2641 - val_accuracy: 0.8840 - val_loss: 0.2513\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.2514 - val_accuracy: 0.8840 - val_loss: 0.2512\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.2491 - val_accuracy: 0.8840 - val_loss: 0.2503\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2508 - val_accuracy: 0.8820 - val_loss: 0.2490\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2632 - val_accuracy: 0.8847 - val_loss: 0.2474\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8828 - loss: 0.2538 - val_accuracy: 0.8833 - val_loss: 0.2470\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.2409 - val_accuracy: 0.8900 - val_loss: 0.2450\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.2437 - val_accuracy: 0.8867 - val_loss: 0.2444\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8865 - loss: 0.2468 - val_accuracy: 0.8887 - val_loss: 0.2438\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2440 - val_accuracy: 0.8860 - val_loss: 0.2421\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2467 - val_accuracy: 0.8853 - val_loss: 0.2425\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.2464 - val_accuracy: 0.8887 - val_loss: 0.2403\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.2313 - val_accuracy: 0.8893 - val_loss: 0.2385\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.2450 - val_accuracy: 0.8860 - val_loss: 0.2374\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.2430 - val_accuracy: 0.8900 - val_loss: 0.2354\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2299 - val_accuracy: 0.8920 - val_loss: 0.2342\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2271 - val_accuracy: 0.8913 - val_loss: 0.2335\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.2308 - val_accuracy: 0.8900 - val_loss: 0.2321\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8976 - loss: 0.2318 - val_accuracy: 0.8913 - val_loss: 0.2299\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.2371 - val_accuracy: 0.8940 - val_loss: 0.2288\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8925 - loss: 0.2327 - val_accuracy: 0.8887 - val_loss: 0.2285\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.2260 - val_accuracy: 0.8940 - val_loss: 0.2273\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.2383 - val_accuracy: 0.8920 - val_loss: 0.2260\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2379 - val_accuracy: 0.8947 - val_loss: 0.2269\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2282 - val_accuracy: 0.8953 - val_loss: 0.2252\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2272 - val_accuracy: 0.8913 - val_loss: 0.2248\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2337 - val_accuracy: 0.8947 - val_loss: 0.2226\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2288 - val_accuracy: 0.8953 - val_loss: 0.2214\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8882 - loss: 0.2243 - val_accuracy: 0.8960 - val_loss: 0.2212\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2211 - val_accuracy: 0.8940 - val_loss: 0.2198\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.2161 - val_accuracy: 0.8967 - val_loss: 0.2168\n",
      "Epoch 38/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2191 - val_accuracy: 0.8940 - val_loss: 0.2185\n",
      "Epoch 39/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2275 - val_accuracy: 0.8953 - val_loss: 0.2160\n",
      "Epoch 40/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.2235 - val_accuracy: 0.8967 - val_loss: 0.2154\n",
      "Epoch 41/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.2152 - val_accuracy: 0.8940 - val_loss: 0.2159\n",
      "Epoch 42/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2197 - val_accuracy: 0.8940 - val_loss: 0.2144\n",
      "Epoch 43/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.2085 - val_accuracy: 0.8947 - val_loss: 0.2141\n",
      "Epoch 44/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2182 - val_accuracy: 0.8960 - val_loss: 0.2124\n",
      "Epoch 45/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2148 - val_accuracy: 0.8967 - val_loss: 0.2135\n",
      "Epoch 46/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.2134 - val_accuracy: 0.8980 - val_loss: 0.2101\n",
      "Epoch 47/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2174 - val_accuracy: 0.8967 - val_loss: 0.2103\n",
      "Epoch 48/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.2134 - val_accuracy: 0.8973 - val_loss: 0.2101\n",
      "Epoch 49/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.2198 - val_accuracy: 0.8967 - val_loss: 0.2102\n",
      "Epoch 50/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2178 - val_accuracy: 0.8973 - val_loss: 0.2102\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.001, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.5483 - val_accuracy: 0.8747 - val_loss: 0.3110\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.3035 - val_accuracy: 0.8813 - val_loss: 0.2680\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.2776 - val_accuracy: 0.8833 - val_loss: 0.2609\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.2731 - val_accuracy: 0.8833 - val_loss: 0.2592\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.2602 - val_accuracy: 0.8827 - val_loss: 0.2582\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.2593 - val_accuracy: 0.8833 - val_loss: 0.2580\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.2527 - val_accuracy: 0.8820 - val_loss: 0.2573\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.2520 - val_accuracy: 0.8820 - val_loss: 0.2563\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.2564 - val_accuracy: 0.8813 - val_loss: 0.2556\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8859 - loss: 0.2525 - val_accuracy: 0.8827 - val_loss: 0.2547\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2475 - val_accuracy: 0.8840 - val_loss: 0.2544\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2540 - val_accuracy: 0.8833 - val_loss: 0.2540\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2484 - val_accuracy: 0.8820 - val_loss: 0.2533\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.2551 - val_accuracy: 0.8833 - val_loss: 0.2523\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2505 - val_accuracy: 0.8847 - val_loss: 0.2508\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.2487 - val_accuracy: 0.8847 - val_loss: 0.2503\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.2409 - val_accuracy: 0.8853 - val_loss: 0.2495\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2557 - val_accuracy: 0.8847 - val_loss: 0.2492\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2463 - val_accuracy: 0.8860 - val_loss: 0.2482\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.2470 - val_accuracy: 0.8873 - val_loss: 0.2459\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.2439 - val_accuracy: 0.8853 - val_loss: 0.2452\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2390 - val_accuracy: 0.8887 - val_loss: 0.2438\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2406 - val_accuracy: 0.8900 - val_loss: 0.2412\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.2466 - val_accuracy: 0.8873 - val_loss: 0.2413\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2290 - val_accuracy: 0.8907 - val_loss: 0.2386\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.2325 - val_accuracy: 0.8893 - val_loss: 0.2367\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.2389 - val_accuracy: 0.8900 - val_loss: 0.2358\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.2290 - val_accuracy: 0.8873 - val_loss: 0.2346\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.2258 - val_accuracy: 0.8927 - val_loss: 0.2322\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2170 - val_accuracy: 0.8947 - val_loss: 0.2304\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2236 - val_accuracy: 0.8933 - val_loss: 0.2292\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.2214 - val_accuracy: 0.8927 - val_loss: 0.2270\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2223 - val_accuracy: 0.8920 - val_loss: 0.2255\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2330 - val_accuracy: 0.8933 - val_loss: 0.2242\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2276 - val_accuracy: 0.8927 - val_loss: 0.2232\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2270 - val_accuracy: 0.8927 - val_loss: 0.2218\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.2311 - val_accuracy: 0.8933 - val_loss: 0.2199\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.2254 - val_accuracy: 0.8987 - val_loss: 0.2191\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.2237 - val_accuracy: 0.8973 - val_loss: 0.2189\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2043 - val_accuracy: 0.8980 - val_loss: 0.2181\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.2139 - val_accuracy: 0.8973 - val_loss: 0.2173\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2107 - val_accuracy: 0.8973 - val_loss: 0.2162\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.2104 - val_accuracy: 0.9000 - val_loss: 0.2163\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.2110 - val_accuracy: 0.8987 - val_loss: 0.2147\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.2198 - val_accuracy: 0.8987 - val_loss: 0.2145\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2076 - val_accuracy: 0.8993 - val_loss: 0.2135\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2099 - val_accuracy: 0.8993 - val_loss: 0.2133\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.2133 - val_accuracy: 0.8980 - val_loss: 0.2137\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2067 - val_accuracy: 0.8987 - val_loss: 0.2134\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2016 - val_accuracy: 0.8987 - val_loss: 0.2125\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.001, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5868 - loss: 0.6730 - val_accuracy: 0.8640 - val_loss: 0.3515\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.3637 - val_accuracy: 0.8747 - val_loss: 0.2824\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3004 - val_accuracy: 0.8793 - val_loss: 0.2664\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.2913 - val_accuracy: 0.8840 - val_loss: 0.2601\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.2800 - val_accuracy: 0.8840 - val_loss: 0.2578\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.2781 - val_accuracy: 0.8840 - val_loss: 0.2576\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2645 - val_accuracy: 0.8847 - val_loss: 0.2569\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.2629 - val_accuracy: 0.8820 - val_loss: 0.2566\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.2615 - val_accuracy: 0.8820 - val_loss: 0.2558\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2645 - val_accuracy: 0.8807 - val_loss: 0.2557\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.2681 - val_accuracy: 0.8820 - val_loss: 0.2555\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2638 - val_accuracy: 0.8820 - val_loss: 0.2551\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.2584 - val_accuracy: 0.8820 - val_loss: 0.2542\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2605 - val_accuracy: 0.8813 - val_loss: 0.2538\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2452 - val_accuracy: 0.8853 - val_loss: 0.2541\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.2497 - val_accuracy: 0.8833 - val_loss: 0.2531\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.2553 - val_accuracy: 0.8807 - val_loss: 0.2527\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2556 - val_accuracy: 0.8840 - val_loss: 0.2515\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.2547 - val_accuracy: 0.8827 - val_loss: 0.2512\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.2437 - val_accuracy: 0.8800 - val_loss: 0.2507\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.2560 - val_accuracy: 0.8813 - val_loss: 0.2509\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2469 - val_accuracy: 0.8820 - val_loss: 0.2496\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.2521 - val_accuracy: 0.8840 - val_loss: 0.2494\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.2393 - val_accuracy: 0.8847 - val_loss: 0.2479\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.2445 - val_accuracy: 0.8847 - val_loss: 0.2474\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.2423 - val_accuracy: 0.8833 - val_loss: 0.2476\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2446 - val_accuracy: 0.8833 - val_loss: 0.2459\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2417 - val_accuracy: 0.8840 - val_loss: 0.2448\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2414 - val_accuracy: 0.8873 - val_loss: 0.2436\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.2492 - val_accuracy: 0.8873 - val_loss: 0.2430\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2504 - val_accuracy: 0.8853 - val_loss: 0.2417\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.2439 - val_accuracy: 0.8880 - val_loss: 0.2400\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2386 - val_accuracy: 0.8867 - val_loss: 0.2389\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2401 - val_accuracy: 0.8873 - val_loss: 0.2380\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2481 - val_accuracy: 0.8867 - val_loss: 0.2370\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2261 - val_accuracy: 0.8860 - val_loss: 0.2359\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2365 - val_accuracy: 0.8873 - val_loss: 0.2353\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2276 - val_accuracy: 0.8867 - val_loss: 0.2342\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.2397 - val_accuracy: 0.8873 - val_loss: 0.2332\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 0.2289 - val_accuracy: 0.8880 - val_loss: 0.2314\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2304 - val_accuracy: 0.8893 - val_loss: 0.2308\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.2264 - val_accuracy: 0.8893 - val_loss: 0.2304\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.2318 - val_accuracy: 0.8887 - val_loss: 0.2287\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.2297 - val_accuracy: 0.8880 - val_loss: 0.2287\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2351 - val_accuracy: 0.8880 - val_loss: 0.2271\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2248 - val_accuracy: 0.8873 - val_loss: 0.2268\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.2341 - val_accuracy: 0.8873 - val_loss: 0.2263\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.2320 - val_accuracy: 0.8887 - val_loss: 0.2252\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2270 - val_accuracy: 0.8887 - val_loss: 0.2248\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2291 - val_accuracy: 0.8887 - val_loss: 0.2239\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.01, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.3382 - val_accuracy: 0.8833 - val_loss: 0.2633\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.2507 - val_accuracy: 0.8793 - val_loss: 0.2531\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.2629 - val_accuracy: 0.8847 - val_loss: 0.2366\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.2308 - val_accuracy: 0.8987 - val_loss: 0.2247\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8925 - loss: 0.2195 - val_accuracy: 0.8913 - val_loss: 0.2234\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8960 - loss: 0.2154 - val_accuracy: 0.8947 - val_loss: 0.2206\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.2117 - val_accuracy: 0.9040 - val_loss: 0.2055\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9020 - loss: 0.2132 - val_accuracy: 0.9007 - val_loss: 0.2080\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2049 - val_accuracy: 0.8947 - val_loss: 0.2084\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2049 - val_accuracy: 0.8980 - val_loss: 0.2032\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.1987 - val_accuracy: 0.9007 - val_loss: 0.2084\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2079 - val_accuracy: 0.9020 - val_loss: 0.2029\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.2006 - val_accuracy: 0.9027 - val_loss: 0.2023\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.2070 - val_accuracy: 0.8967 - val_loss: 0.2042\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9017 - loss: 0.2069 - val_accuracy: 0.8980 - val_loss: 0.2066\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.1952 - val_accuracy: 0.9047 - val_loss: 0.2057\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.01, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.3450 - val_accuracy: 0.8780 - val_loss: 0.2606\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.2613 - val_accuracy: 0.8833 - val_loss: 0.2473\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2494 - val_accuracy: 0.8853 - val_loss: 0.2414\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2335 - val_accuracy: 0.8940 - val_loss: 0.2319\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.2426 - val_accuracy: 0.8920 - val_loss: 0.2266\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2410 - val_accuracy: 0.8953 - val_loss: 0.2208\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.2294 - val_accuracy: 0.8960 - val_loss: 0.2189\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2201 - val_accuracy: 0.8947 - val_loss: 0.2151\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2252 - val_accuracy: 0.8980 - val_loss: 0.2135\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2172 - val_accuracy: 0.8953 - val_loss: 0.2117\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2230 - val_accuracy: 0.9000 - val_loss: 0.2109\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2233 - val_accuracy: 0.8993 - val_loss: 0.2074\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.2125 - val_accuracy: 0.8987 - val_loss: 0.2073\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8951 - loss: 0.2170 - val_accuracy: 0.8967 - val_loss: 0.2096\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.2231 - val_accuracy: 0.8847 - val_loss: 0.2215\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.2258 - val_accuracy: 0.9020 - val_loss: 0.2080\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.01, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.3752 - val_accuracy: 0.8807 - val_loss: 0.2589\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.2615 - val_accuracy: 0.8840 - val_loss: 0.2521\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.2553 - val_accuracy: 0.8793 - val_loss: 0.2452\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8823 - loss: 0.2512 - val_accuracy: 0.8913 - val_loss: 0.2330\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2423 - val_accuracy: 0.8893 - val_loss: 0.2339\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2125 - val_accuracy: 0.8940 - val_loss: 0.2154\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.2086 - val_accuracy: 0.8967 - val_loss: 0.2122\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8962 - loss: 0.2118 - val_accuracy: 0.8940 - val_loss: 0.2107\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2143 - val_accuracy: 0.8987 - val_loss: 0.2099\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9113 - loss: 0.1964 - val_accuracy: 0.9000 - val_loss: 0.2096\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.2100 - val_accuracy: 0.8993 - val_loss: 0.2034\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2046 - val_accuracy: 0.9020 - val_loss: 0.2034\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9022 - loss: 0.2055 - val_accuracy: 0.8960 - val_loss: 0.2072\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.1985 - val_accuracy: 0.9013 - val_loss: 0.2016\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.1903 - val_accuracy: 0.9040 - val_loss: 0.1994\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2017 - val_accuracy: 0.8927 - val_loss: 0.2049\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.1984 - val_accuracy: 0.9000 - val_loss: 0.2010\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.1934 - val_accuracy: 0.8987 - val_loss: 0.2021\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=32, learning_rate=0.01, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.3562 - val_accuracy: 0.8833 - val_loss: 0.2584\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2636 - val_accuracy: 0.8793 - val_loss: 0.2539\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.2513 - val_accuracy: 0.8840 - val_loss: 0.2477\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2578 - val_accuracy: 0.8847 - val_loss: 0.2456\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2349 - val_accuracy: 0.8840 - val_loss: 0.2370\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.2478 - val_accuracy: 0.8867 - val_loss: 0.2313\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.2429 - val_accuracy: 0.8953 - val_loss: 0.2215\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2229 - val_accuracy: 0.8900 - val_loss: 0.2197\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.2302 - val_accuracy: 0.8933 - val_loss: 0.2193\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2279 - val_accuracy: 0.8980 - val_loss: 0.2125\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2271 - val_accuracy: 0.9020 - val_loss: 0.2093\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2161 - val_accuracy: 0.9033 - val_loss: 0.2105\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2144 - val_accuracy: 0.8933 - val_loss: 0.2136\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2097 - val_accuracy: 0.8973 - val_loss: 0.2116\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.001, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4515 - val_accuracy: 0.8820 - val_loss: 0.2645\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.2619 - val_accuracy: 0.8860 - val_loss: 0.2565\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.2546 - val_accuracy: 0.8813 - val_loss: 0.2553\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2573 - val_accuracy: 0.8853 - val_loss: 0.2555\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.2551 - val_accuracy: 0.8860 - val_loss: 0.2564\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.2610 - val_accuracy: 0.8827 - val_loss: 0.2548\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2571 - val_accuracy: 0.8827 - val_loss: 0.2533\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2350 - val_accuracy: 0.8847 - val_loss: 0.2521\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2382 - val_accuracy: 0.8847 - val_loss: 0.2530\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.2411 - val_accuracy: 0.8820 - val_loss: 0.2514\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8944 - loss: 0.2297 - val_accuracy: 0.8847 - val_loss: 0.2504\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8883 - loss: 0.2424 - val_accuracy: 0.8840 - val_loss: 0.2498\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.2449 - val_accuracy: 0.8880 - val_loss: 0.2473\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.2425 - val_accuracy: 0.8893 - val_loss: 0.2445\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8981 - loss: 0.2279 - val_accuracy: 0.8880 - val_loss: 0.2431\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.2343 - val_accuracy: 0.8873 - val_loss: 0.2410\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.2303 - val_accuracy: 0.8893 - val_loss: 0.2376\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2269 - val_accuracy: 0.8920 - val_loss: 0.2355\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.2206 - val_accuracy: 0.8927 - val_loss: 0.2338\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9028 - loss: 0.2193 - val_accuracy: 0.8913 - val_loss: 0.2316\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8945 - loss: 0.2205 - val_accuracy: 0.8940 - val_loss: 0.2282\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8923 - loss: 0.2291 - val_accuracy: 0.8920 - val_loss: 0.2270\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.2132 - val_accuracy: 0.8947 - val_loss: 0.2265\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2231 - val_accuracy: 0.8947 - val_loss: 0.2236\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.2178 - val_accuracy: 0.8940 - val_loss: 0.2218\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2161 - val_accuracy: 0.8933 - val_loss: 0.2208\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.2195 - val_accuracy: 0.8933 - val_loss: 0.2202\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2189 - val_accuracy: 0.8947 - val_loss: 0.2185\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2133 - val_accuracy: 0.8967 - val_loss: 0.2172\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2089 - val_accuracy: 0.8967 - val_loss: 0.2163\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2103 - val_accuracy: 0.8993 - val_loss: 0.2148\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2065 - val_accuracy: 0.8987 - val_loss: 0.2128\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2114 - val_accuracy: 0.9013 - val_loss: 0.2135\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2128 - val_accuracy: 0.9020 - val_loss: 0.2128\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.1945 - val_accuracy: 0.9007 - val_loss: 0.2118\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1955 - val_accuracy: 0.8973 - val_loss: 0.2112\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.1933 - val_accuracy: 0.9000 - val_loss: 0.2090\n",
      "Epoch 38/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1971 - val_accuracy: 0.9000 - val_loss: 0.2084\n",
      "Epoch 39/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1976 - val_accuracy: 0.8993 - val_loss: 0.2079\n",
      "Epoch 40/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2010 - val_accuracy: 0.9007 - val_loss: 0.2071\n",
      "Epoch 41/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9020 - loss: 0.2072 - val_accuracy: 0.8993 - val_loss: 0.2077\n",
      "Epoch 42/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1986 - val_accuracy: 0.8993 - val_loss: 0.2065\n",
      "Epoch 43/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.1997 - val_accuracy: 0.8993 - val_loss: 0.2076\n",
      "Epoch 44/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1966 - val_accuracy: 0.8993 - val_loss: 0.2066\n",
      "Epoch 45/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.1968 - val_accuracy: 0.9000 - val_loss: 0.2061\n",
      "Epoch 46/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.1995 - val_accuracy: 0.8993 - val_loss: 0.2046\n",
      "Epoch 47/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.1962 - val_accuracy: 0.9000 - val_loss: 0.2069\n",
      "Epoch 48/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.1957 - val_accuracy: 0.8980 - val_loss: 0.2055\n",
      "Epoch 49/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.1957 - val_accuracy: 0.9007 - val_loss: 0.2041\n",
      "Epoch 50/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.1929 - val_accuracy: 0.9033 - val_loss: 0.2040\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.001, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.4811 - val_accuracy: 0.8773 - val_loss: 0.2665\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8773 - loss: 0.2785 - val_accuracy: 0.8833 - val_loss: 0.2578\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.2620 - val_accuracy: 0.8840 - val_loss: 0.2559\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.2666 - val_accuracy: 0.8813 - val_loss: 0.2557\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2572 - val_accuracy: 0.8820 - val_loss: 0.2575\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.2584 - val_accuracy: 0.8833 - val_loss: 0.2560\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2573 - val_accuracy: 0.8833 - val_loss: 0.2545\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.2552 - val_accuracy: 0.8827 - val_loss: 0.2535\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8872 - loss: 0.2518 - val_accuracy: 0.8840 - val_loss: 0.2520\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2448 - val_accuracy: 0.8833 - val_loss: 0.2510\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2480 - val_accuracy: 0.8827 - val_loss: 0.2505\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.2453 - val_accuracy: 0.8840 - val_loss: 0.2475\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.2443 - val_accuracy: 0.8813 - val_loss: 0.2462\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2490 - val_accuracy: 0.8840 - val_loss: 0.2447\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.2395 - val_accuracy: 0.8853 - val_loss: 0.2426\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2379 - val_accuracy: 0.8853 - val_loss: 0.2406\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.2454 - val_accuracy: 0.8867 - val_loss: 0.2393\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2282 - val_accuracy: 0.8873 - val_loss: 0.2369\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8966 - loss: 0.2315 - val_accuracy: 0.8893 - val_loss: 0.2352\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2334 - val_accuracy: 0.8900 - val_loss: 0.2324\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2356 - val_accuracy: 0.8933 - val_loss: 0.2299\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.2247 - val_accuracy: 0.8893 - val_loss: 0.2288\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2282 - val_accuracy: 0.8927 - val_loss: 0.2280\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2289 - val_accuracy: 0.8920 - val_loss: 0.2245\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2149 - val_accuracy: 0.8907 - val_loss: 0.2226\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.2231 - val_accuracy: 0.8927 - val_loss: 0.2216\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2175 - val_accuracy: 0.8940 - val_loss: 0.2209\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2308 - val_accuracy: 0.8933 - val_loss: 0.2189\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2186 - val_accuracy: 0.8973 - val_loss: 0.2178\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2136 - val_accuracy: 0.8967 - val_loss: 0.2171\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9020 - loss: 0.2137 - val_accuracy: 0.8967 - val_loss: 0.2169\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.2141 - val_accuracy: 0.8980 - val_loss: 0.2163\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2209 - val_accuracy: 0.8960 - val_loss: 0.2149\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.2174 - val_accuracy: 0.8973 - val_loss: 0.2128\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2039 - val_accuracy: 0.8980 - val_loss: 0.2127\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2178 - val_accuracy: 0.8960 - val_loss: 0.2122\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2004 - val_accuracy: 0.8953 - val_loss: 0.2100\n",
      "Epoch 38/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2085 - val_accuracy: 0.8987 - val_loss: 0.2094\n",
      "Epoch 39/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2117 - val_accuracy: 0.8960 - val_loss: 0.2104\n",
      "Epoch 40/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2109 - val_accuracy: 0.8967 - val_loss: 0.2108\n",
      "Epoch 41/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.2030 - val_accuracy: 0.8967 - val_loss: 0.2075\n",
      "Epoch 42/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.2089 - val_accuracy: 0.8960 - val_loss: 0.2082\n",
      "Epoch 43/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9010 - loss: 0.2071 - val_accuracy: 0.8967 - val_loss: 0.2087\n",
      "Epoch 44/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9010 - loss: 0.2077 - val_accuracy: 0.8967 - val_loss: 0.2070\n",
      "Epoch 45/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9023 - loss: 0.2014 - val_accuracy: 0.8973 - val_loss: 0.2076\n",
      "Epoch 46/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.1968 - val_accuracy: 0.8973 - val_loss: 0.2071\n",
      "Epoch 47/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.2009 - val_accuracy: 0.8973 - val_loss: 0.2055\n",
      "Epoch 48/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.1890 - val_accuracy: 0.8973 - val_loss: 0.2054\n",
      "Epoch 49/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1998 - val_accuracy: 0.8973 - val_loss: 0.2058\n",
      "Epoch 50/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.1995 - val_accuracy: 0.9000 - val_loss: 0.2048\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.001, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.4794 - val_accuracy: 0.8787 - val_loss: 0.2796\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8720 - loss: 0.2892 - val_accuracy: 0.8840 - val_loss: 0.2587\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2652 - val_accuracy: 0.8820 - val_loss: 0.2570\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2600 - val_accuracy: 0.8833 - val_loss: 0.2556\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2480 - val_accuracy: 0.8827 - val_loss: 0.2554\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.2596 - val_accuracy: 0.8813 - val_loss: 0.2550\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2458 - val_accuracy: 0.8807 - val_loss: 0.2565\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2523 - val_accuracy: 0.8833 - val_loss: 0.2551\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.2460 - val_accuracy: 0.8853 - val_loss: 0.2558\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.001, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6711 - loss: 0.5840 - val_accuracy: 0.8787 - val_loss: 0.2938\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.3013 - val_accuracy: 0.8813 - val_loss: 0.2634\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.2813 - val_accuracy: 0.8840 - val_loss: 0.2582\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.2647 - val_accuracy: 0.8820 - val_loss: 0.2583\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2662 - val_accuracy: 0.8847 - val_loss: 0.2559\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.2599 - val_accuracy: 0.8867 - val_loss: 0.2551\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.2602 - val_accuracy: 0.8827 - val_loss: 0.2555\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.2635 - val_accuracy: 0.8840 - val_loss: 0.2546\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2672 - val_accuracy: 0.8820 - val_loss: 0.2551\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.2551 - val_accuracy: 0.8820 - val_loss: 0.2535\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2577 - val_accuracy: 0.8827 - val_loss: 0.2526\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.2592 - val_accuracy: 0.8813 - val_loss: 0.2532\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2467 - val_accuracy: 0.8840 - val_loss: 0.2522\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2478 - val_accuracy: 0.8827 - val_loss: 0.2511\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2485 - val_accuracy: 0.8853 - val_loss: 0.2501\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8891 - loss: 0.2480 - val_accuracy: 0.8847 - val_loss: 0.2493\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.2497 - val_accuracy: 0.8833 - val_loss: 0.2487\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.2360 - val_accuracy: 0.8833 - val_loss: 0.2476\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.2412 - val_accuracy: 0.8853 - val_loss: 0.2458\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2474 - val_accuracy: 0.8840 - val_loss: 0.2451\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.2414 - val_accuracy: 0.8853 - val_loss: 0.2435\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2320 - val_accuracy: 0.8847 - val_loss: 0.2432\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2337 - val_accuracy: 0.8840 - val_loss: 0.2418\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2348 - val_accuracy: 0.8853 - val_loss: 0.2409\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.2411 - val_accuracy: 0.8873 - val_loss: 0.2386\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2332 - val_accuracy: 0.8900 - val_loss: 0.2368\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.2382 - val_accuracy: 0.8880 - val_loss: 0.2359\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2194 - val_accuracy: 0.8893 - val_loss: 0.2348\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.2289 - val_accuracy: 0.8920 - val_loss: 0.2319\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9008 - loss: 0.2173 - val_accuracy: 0.8920 - val_loss: 0.2310\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2273 - val_accuracy: 0.8920 - val_loss: 0.2295\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2194 - val_accuracy: 0.8947 - val_loss: 0.2286\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2236 - val_accuracy: 0.8927 - val_loss: 0.2277\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.2265 - val_accuracy: 0.8920 - val_loss: 0.2254\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2176 - val_accuracy: 0.8927 - val_loss: 0.2240\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.2162 - val_accuracy: 0.8920 - val_loss: 0.2233\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2270 - val_accuracy: 0.8927 - val_loss: 0.2232\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.2197 - val_accuracy: 0.8913 - val_loss: 0.2208\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2153 - val_accuracy: 0.8953 - val_loss: 0.2204\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2091 - val_accuracy: 0.8940 - val_loss: 0.2186\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2218 - val_accuracy: 0.8973 - val_loss: 0.2172\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2178 - val_accuracy: 0.8960 - val_loss: 0.2174\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2086 - val_accuracy: 0.8960 - val_loss: 0.2156\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2120 - val_accuracy: 0.8980 - val_loss: 0.2160\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2066 - val_accuracy: 0.8967 - val_loss: 0.2146\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2123 - val_accuracy: 0.8980 - val_loss: 0.2134\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.2050 - val_accuracy: 0.8987 - val_loss: 0.2132\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2072 - val_accuracy: 0.9007 - val_loss: 0.2112\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2119 - val_accuracy: 0.8980 - val_loss: 0.2117\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2021 - val_accuracy: 0.8967 - val_loss: 0.2112\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.01, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.3035 - val_accuracy: 0.8860 - val_loss: 0.2545\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2513 - val_accuracy: 0.8913 - val_loss: 0.2398\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2247 - val_accuracy: 0.8953 - val_loss: 0.2277\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2058 - val_accuracy: 0.8820 - val_loss: 0.2356\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.2215 - val_accuracy: 0.8960 - val_loss: 0.2092\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.2193 - val_accuracy: 0.8967 - val_loss: 0.2061\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.2013 - val_accuracy: 0.9033 - val_loss: 0.2039\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2030 - val_accuracy: 0.8947 - val_loss: 0.2077\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2113 - val_accuracy: 0.8980 - val_loss: 0.2055\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2004 - val_accuracy: 0.9007 - val_loss: 0.2012\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.1931 - val_accuracy: 0.8987 - val_loss: 0.2038\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.1990 - val_accuracy: 0.9040 - val_loss: 0.2020\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.1996 - val_accuracy: 0.9013 - val_loss: 0.1986\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.1988 - val_accuracy: 0.8973 - val_loss: 0.2039\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.2045 - val_accuracy: 0.9000 - val_loss: 0.2001\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.1952 - val_accuracy: 0.9000 - val_loss: 0.1978\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.2041 - val_accuracy: 0.8933 - val_loss: 0.2045\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.2036 - val_accuracy: 0.9020 - val_loss: 0.2016\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.1990 - val_accuracy: 0.8960 - val_loss: 0.2047\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.01, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8545 - loss: 0.3129 - val_accuracy: 0.8833 - val_loss: 0.2518\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2639 - val_accuracy: 0.8767 - val_loss: 0.2483\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.2473 - val_accuracy: 0.8800 - val_loss: 0.2354\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.2324 - val_accuracy: 0.8820 - val_loss: 0.2333\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2342 - val_accuracy: 0.8900 - val_loss: 0.2248\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2332 - val_accuracy: 0.9027 - val_loss: 0.2135\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.2225 - val_accuracy: 0.8960 - val_loss: 0.2111\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2190 - val_accuracy: 0.8913 - val_loss: 0.2183\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9020 - loss: 0.2175 - val_accuracy: 0.8973 - val_loss: 0.2147\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.2121 - val_accuracy: 0.8913 - val_loss: 0.2078\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.2215 - val_accuracy: 0.8973 - val_loss: 0.2043\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2184 - val_accuracy: 0.8980 - val_loss: 0.2066\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2106 - val_accuracy: 0.8913 - val_loss: 0.2064\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2113 - val_accuracy: 0.9020 - val_loss: 0.2075\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.01, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8490 - loss: 0.3224 - val_accuracy: 0.8820 - val_loss: 0.2594\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8806 - loss: 0.2637 - val_accuracy: 0.8787 - val_loss: 0.2546\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2521 - val_accuracy: 0.8867 - val_loss: 0.2385\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2314 - val_accuracy: 0.8800 - val_loss: 0.2337\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2284 - val_accuracy: 0.8967 - val_loss: 0.2184\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2091 - val_accuracy: 0.9000 - val_loss: 0.2137\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.2196 - val_accuracy: 0.8967 - val_loss: 0.2097\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2108 - val_accuracy: 0.8940 - val_loss: 0.2081\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2042 - val_accuracy: 0.9007 - val_loss: 0.2034\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2032 - val_accuracy: 0.8967 - val_loss: 0.2100\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2013 - val_accuracy: 0.8927 - val_loss: 0.2075\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.1978 - val_accuracy: 0.8980 - val_loss: 0.2045\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=64, learning_rate=0.01, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.3292 - val_accuracy: 0.8793 - val_loss: 0.2609\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8865 - loss: 0.2501 - val_accuracy: 0.8833 - val_loss: 0.2510\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.2475 - val_accuracy: 0.8873 - val_loss: 0.2414\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2372 - val_accuracy: 0.8813 - val_loss: 0.2379\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2286 - val_accuracy: 0.8940 - val_loss: 0.2262\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.2298 - val_accuracy: 0.8953 - val_loss: 0.2182\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2225 - val_accuracy: 0.9007 - val_loss: 0.2152\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2208 - val_accuracy: 0.9000 - val_loss: 0.2116\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.2037 - val_accuracy: 0.9013 - val_loss: 0.2078\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2191 - val_accuracy: 0.9000 - val_loss: 0.2087\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.2042 - val_accuracy: 0.8953 - val_loss: 0.2109\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.1998 - val_accuracy: 0.8973 - val_loss: 0.2075\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2116 - val_accuracy: 0.8973 - val_loss: 0.2063\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.2052 - val_accuracy: 0.8960 - val_loss: 0.2099\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2068 - val_accuracy: 0.8960 - val_loss: 0.2070\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2070 - val_accuracy: 0.8987 - val_loss: 0.2063\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2033 - val_accuracy: 0.9013 - val_loss: 0.2070\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.1973 - val_accuracy: 0.8927 - val_loss: 0.2031\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.2009 - val_accuracy: 0.8980 - val_loss: 0.2046\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.1970 - val_accuracy: 0.9027 - val_loss: 0.2000\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.1991 - val_accuracy: 0.9013 - val_loss: 0.2052\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2021 - val_accuracy: 0.8953 - val_loss: 0.2017\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2046 - val_accuracy: 0.8960 - val_loss: 0.2024\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.001, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.4431 - val_accuracy: 0.8847 - val_loss: 0.2608\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.2553 - val_accuracy: 0.8847 - val_loss: 0.2582\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.2526 - val_accuracy: 0.8820 - val_loss: 0.2554\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2418 - val_accuracy: 0.8827 - val_loss: 0.2553\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.2503 - val_accuracy: 0.8813 - val_loss: 0.2546\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.2451 - val_accuracy: 0.8833 - val_loss: 0.2550\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2487 - val_accuracy: 0.8847 - val_loss: 0.2529\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.2413 - val_accuracy: 0.8847 - val_loss: 0.2511\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2495 - val_accuracy: 0.8827 - val_loss: 0.2517\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.2424 - val_accuracy: 0.8847 - val_loss: 0.2502\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.2267 - val_accuracy: 0.8820 - val_loss: 0.2475\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2331 - val_accuracy: 0.8860 - val_loss: 0.2440\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2269 - val_accuracy: 0.8920 - val_loss: 0.2389\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2278 - val_accuracy: 0.8900 - val_loss: 0.2374\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2333 - val_accuracy: 0.8900 - val_loss: 0.2347\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2198 - val_accuracy: 0.8920 - val_loss: 0.2301\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2263 - val_accuracy: 0.8947 - val_loss: 0.2263\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.2143 - val_accuracy: 0.8973 - val_loss: 0.2244\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2140 - val_accuracy: 0.8960 - val_loss: 0.2205\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2172 - val_accuracy: 0.8973 - val_loss: 0.2184\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2014 - val_accuracy: 0.8993 - val_loss: 0.2180\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2143 - val_accuracy: 0.9013 - val_loss: 0.2151\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2206 - val_accuracy: 0.8987 - val_loss: 0.2141\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.2031 - val_accuracy: 0.8993 - val_loss: 0.2133\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2043 - val_accuracy: 0.8987 - val_loss: 0.2103\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.1972 - val_accuracy: 0.8993 - val_loss: 0.2089\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.2043 - val_accuracy: 0.8993 - val_loss: 0.2074\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2010 - val_accuracy: 0.8987 - val_loss: 0.2083\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2034 - val_accuracy: 0.8973 - val_loss: 0.2117\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.2015 - val_accuracy: 0.9013 - val_loss: 0.2060\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.1995 - val_accuracy: 0.9007 - val_loss: 0.2049\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2048 - val_accuracy: 0.9013 - val_loss: 0.2056\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.1941 - val_accuracy: 0.8987 - val_loss: 0.2074\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.1894 - val_accuracy: 0.8980 - val_loss: 0.2045\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.1875 - val_accuracy: 0.9000 - val_loss: 0.2041\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1936 - val_accuracy: 0.9027 - val_loss: 0.2021\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9023 - loss: 0.1971 - val_accuracy: 0.9033 - val_loss: 0.2023\n",
      "Epoch 38/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.1904 - val_accuracy: 0.9027 - val_loss: 0.2029\n",
      "Epoch 39/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.1948 - val_accuracy: 0.9020 - val_loss: 0.2017\n",
      "Epoch 40/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.1861 - val_accuracy: 0.9013 - val_loss: 0.2020\n",
      "Epoch 41/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.1891 - val_accuracy: 0.8967 - val_loss: 0.2028\n",
      "Epoch 42/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.1835 - val_accuracy: 0.9013 - val_loss: 0.2019\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.001, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.4290 - val_accuracy: 0.8847 - val_loss: 0.2588\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8764 - loss: 0.2695 - val_accuracy: 0.8833 - val_loss: 0.2549\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8899 - loss: 0.2443 - val_accuracy: 0.8827 - val_loss: 0.2549\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.2547 - val_accuracy: 0.8813 - val_loss: 0.2567\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.2596 - val_accuracy: 0.8853 - val_loss: 0.2537\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8901 - loss: 0.2479 - val_accuracy: 0.8867 - val_loss: 0.2534\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.2331 - val_accuracy: 0.8847 - val_loss: 0.2530\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.2457 - val_accuracy: 0.8833 - val_loss: 0.2510\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2473 - val_accuracy: 0.8827 - val_loss: 0.2487\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.2495 - val_accuracy: 0.8827 - val_loss: 0.2477\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8843 - loss: 0.2419 - val_accuracy: 0.8840 - val_loss: 0.2471\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2368 - val_accuracy: 0.8827 - val_loss: 0.2440\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.2460 - val_accuracy: 0.8867 - val_loss: 0.2407\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2217 - val_accuracy: 0.8887 - val_loss: 0.2383\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8953 - loss: 0.2302 - val_accuracy: 0.8933 - val_loss: 0.2330\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2239 - val_accuracy: 0.8873 - val_loss: 0.2324\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2163 - val_accuracy: 0.8960 - val_loss: 0.2264\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.2119 - val_accuracy: 0.8940 - val_loss: 0.2233\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2137 - val_accuracy: 0.8940 - val_loss: 0.2217\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.2043 - val_accuracy: 0.8953 - val_loss: 0.2186\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.2157 - val_accuracy: 0.8993 - val_loss: 0.2169\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.2061 - val_accuracy: 0.9007 - val_loss: 0.2143\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2043 - val_accuracy: 0.8993 - val_loss: 0.2130\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2094 - val_accuracy: 0.8987 - val_loss: 0.2120\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2068 - val_accuracy: 0.8987 - val_loss: 0.2112\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2042 - val_accuracy: 0.9013 - val_loss: 0.2103\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.1982 - val_accuracy: 0.9000 - val_loss: 0.2091\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2020 - val_accuracy: 0.8980 - val_loss: 0.2081\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2007 - val_accuracy: 0.8967 - val_loss: 0.2070\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.2052 - val_accuracy: 0.8980 - val_loss: 0.2078\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.1904 - val_accuracy: 0.8987 - val_loss: 0.2076\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.1973 - val_accuracy: 0.8993 - val_loss: 0.2076\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.001, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4540 - val_accuracy: 0.8800 - val_loss: 0.2646\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.2631 - val_accuracy: 0.8800 - val_loss: 0.2590\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.2454 - val_accuracy: 0.8793 - val_loss: 0.2554\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2312 - val_accuracy: 0.8840 - val_loss: 0.2540\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8897 - loss: 0.2411 - val_accuracy: 0.8800 - val_loss: 0.2552\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2402 - val_accuracy: 0.8780 - val_loss: 0.2541\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.2500 - val_accuracy: 0.8813 - val_loss: 0.2534\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.2410 - val_accuracy: 0.8840 - val_loss: 0.2522\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2399 - val_accuracy: 0.8807 - val_loss: 0.2509\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.2452 - val_accuracy: 0.8900 - val_loss: 0.2495\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.2307 - val_accuracy: 0.8833 - val_loss: 0.2491\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2396 - val_accuracy: 0.8840 - val_loss: 0.2492\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2396 - val_accuracy: 0.8813 - val_loss: 0.2491\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2384 - val_accuracy: 0.8853 - val_loss: 0.2450\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8927 - loss: 0.2313 - val_accuracy: 0.8867 - val_loss: 0.2438\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.2374 - val_accuracy: 0.8893 - val_loss: 0.2408\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2263 - val_accuracy: 0.8920 - val_loss: 0.2393\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2256 - val_accuracy: 0.8967 - val_loss: 0.2359\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.2222 - val_accuracy: 0.8960 - val_loss: 0.2348\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2330 - val_accuracy: 0.8933 - val_loss: 0.2340\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8929 - loss: 0.2245 - val_accuracy: 0.8967 - val_loss: 0.2304\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8936 - loss: 0.2205 - val_accuracy: 0.8947 - val_loss: 0.2290\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.2249 - val_accuracy: 0.8973 - val_loss: 0.2273\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.2265 - val_accuracy: 0.8913 - val_loss: 0.2266\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.2274 - val_accuracy: 0.8947 - val_loss: 0.2250\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2137 - val_accuracy: 0.8953 - val_loss: 0.2241\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2183 - val_accuracy: 0.8980 - val_loss: 0.2219\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2089 - val_accuracy: 0.8987 - val_loss: 0.2204\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.2130 - val_accuracy: 0.8980 - val_loss: 0.2193\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9031 - loss: 0.2116 - val_accuracy: 0.8967 - val_loss: 0.2182\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8992 - loss: 0.2134 - val_accuracy: 0.8973 - val_loss: 0.2165\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8966 - loss: 0.2132 - val_accuracy: 0.8987 - val_loss: 0.2154\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8993 - loss: 0.2080 - val_accuracy: 0.9000 - val_loss: 0.2138\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.2024 - val_accuracy: 0.8993 - val_loss: 0.2141\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2000 - val_accuracy: 0.8993 - val_loss: 0.2128\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.2027 - val_accuracy: 0.8993 - val_loss: 0.2130\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.2015 - val_accuracy: 0.8993 - val_loss: 0.2105\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.1936 - val_accuracy: 0.8980 - val_loss: 0.2106\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.1963 - val_accuracy: 0.8980 - val_loss: 0.2086\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.2076 - val_accuracy: 0.8980 - val_loss: 0.2097\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.2055 - val_accuracy: 0.8960 - val_loss: 0.2094\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.1943 - val_accuracy: 0.8960 - val_loss: 0.2094\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.001, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.4603 - val_accuracy: 0.8807 - val_loss: 0.2676\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2666 - val_accuracy: 0.8847 - val_loss: 0.2584\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8801 - loss: 0.2588 - val_accuracy: 0.8840 - val_loss: 0.2569\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8823 - loss: 0.2541 - val_accuracy: 0.8833 - val_loss: 0.2574\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.2443 - val_accuracy: 0.8820 - val_loss: 0.2559\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.2487 - val_accuracy: 0.8827 - val_loss: 0.2552\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.2524 - val_accuracy: 0.8847 - val_loss: 0.2544\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.2449 - val_accuracy: 0.8807 - val_loss: 0.2554\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2426 - val_accuracy: 0.8807 - val_loss: 0.2530\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.2500 - val_accuracy: 0.8833 - val_loss: 0.2523\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2411 - val_accuracy: 0.8847 - val_loss: 0.2516\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2465 - val_accuracy: 0.8840 - val_loss: 0.2513\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.2372 - val_accuracy: 0.8833 - val_loss: 0.2512\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8865 - loss: 0.2449 - val_accuracy: 0.8847 - val_loss: 0.2494\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2506 - val_accuracy: 0.8847 - val_loss: 0.2472\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.2502 - val_accuracy: 0.8853 - val_loss: 0.2460\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2495 - val_accuracy: 0.8847 - val_loss: 0.2454\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2447 - val_accuracy: 0.8860 - val_loss: 0.2439\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2380 - val_accuracy: 0.8860 - val_loss: 0.2424\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2363 - val_accuracy: 0.8853 - val_loss: 0.2398\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2300 - val_accuracy: 0.8907 - val_loss: 0.2374\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.2302 - val_accuracy: 0.8893 - val_loss: 0.2361\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2282 - val_accuracy: 0.8893 - val_loss: 0.2345\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.2277 - val_accuracy: 0.8920 - val_loss: 0.2324\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.2269 - val_accuracy: 0.8887 - val_loss: 0.2310\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8898 - loss: 0.2253 - val_accuracy: 0.8953 - val_loss: 0.2275\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 0.2182 - val_accuracy: 0.8953 - val_loss: 0.2265\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.2224 - val_accuracy: 0.8947 - val_loss: 0.2246\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2218 - val_accuracy: 0.8887 - val_loss: 0.2231\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2157 - val_accuracy: 0.8927 - val_loss: 0.2205\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.2184 - val_accuracy: 0.8927 - val_loss: 0.2200\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2199 - val_accuracy: 0.8987 - val_loss: 0.2176\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.2080 - val_accuracy: 0.9000 - val_loss: 0.2151\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.2091 - val_accuracy: 0.8953 - val_loss: 0.2155\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2027 - val_accuracy: 0.8987 - val_loss: 0.2132\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2119 - val_accuracy: 0.8993 - val_loss: 0.2129\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2116 - val_accuracy: 0.8987 - val_loss: 0.2118\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.1982 - val_accuracy: 0.9000 - val_loss: 0.2113\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.1983 - val_accuracy: 0.8993 - val_loss: 0.2102\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2074 - val_accuracy: 0.8993 - val_loss: 0.2098\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.1945 - val_accuracy: 0.9007 - val_loss: 0.2092\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2010 - val_accuracy: 0.8973 - val_loss: 0.2103\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2012 - val_accuracy: 0.8987 - val_loss: 0.2075\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2016 - val_accuracy: 0.8980 - val_loss: 0.2081\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.2080 - val_accuracy: 0.8980 - val_loss: 0.2074\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.1940 - val_accuracy: 0.8973 - val_loss: 0.2068\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9050 - loss: 0.1928 - val_accuracy: 0.8993 - val_loss: 0.2061\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.1913 - val_accuracy: 0.9000 - val_loss: 0.2054\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.2043 - val_accuracy: 0.9000 - val_loss: 0.2050\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.2005 - val_accuracy: 0.8987 - val_loss: 0.2050\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.01, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.2935 - val_accuracy: 0.8820 - val_loss: 0.2533\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.2431 - val_accuracy: 0.8873 - val_loss: 0.2365\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2277 - val_accuracy: 0.8927 - val_loss: 0.2194\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2183 - val_accuracy: 0.8940 - val_loss: 0.2178\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2127 - val_accuracy: 0.8953 - val_loss: 0.2155\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2109 - val_accuracy: 0.9000 - val_loss: 0.2104\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2030 - val_accuracy: 0.8993 - val_loss: 0.2068\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.2015 - val_accuracy: 0.9053 - val_loss: 0.2018\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.2129 - val_accuracy: 0.8967 - val_loss: 0.2095\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2027 - val_accuracy: 0.8947 - val_loss: 0.2054\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.1916 - val_accuracy: 0.9000 - val_loss: 0.2046\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.01, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 0.2968 - val_accuracy: 0.8800 - val_loss: 0.2659\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.2590 - val_accuracy: 0.8927 - val_loss: 0.2378\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.2376 - val_accuracy: 0.8960 - val_loss: 0.2255\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2236 - val_accuracy: 0.9000 - val_loss: 0.2125\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.2237 - val_accuracy: 0.9000 - val_loss: 0.2162\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2147 - val_accuracy: 0.8973 - val_loss: 0.2065\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.2215 - val_accuracy: 0.8880 - val_loss: 0.2205\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 0.2160 - val_accuracy: 0.9020 - val_loss: 0.2057\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.2217 - val_accuracy: 0.9000 - val_loss: 0.2065\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2129 - val_accuracy: 0.9020 - val_loss: 0.2070\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.2172 - val_accuracy: 0.8987 - val_loss: 0.2053\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2121 - val_accuracy: 0.8907 - val_loss: 0.2079\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.2059 - val_accuracy: 0.8960 - val_loss: 0.2044\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.2127 - val_accuracy: 0.9027 - val_loss: 0.2039\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2153 - val_accuracy: 0.9020 - val_loss: 0.2025\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2097 - val_accuracy: 0.9067 - val_loss: 0.2033\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.2029 - val_accuracy: 0.9000 - val_loss: 0.2116\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2124 - val_accuracy: 0.8993 - val_loss: 0.2079\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.01, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3309 - val_accuracy: 0.8760 - val_loss: 0.2601\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.2481 - val_accuracy: 0.8913 - val_loss: 0.2374\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.2339 - val_accuracy: 0.8913 - val_loss: 0.2321\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.2271 - val_accuracy: 0.8980 - val_loss: 0.2148\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.2202 - val_accuracy: 0.8967 - val_loss: 0.2159\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2088 - val_accuracy: 0.8993 - val_loss: 0.2136\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2006 - val_accuracy: 0.9007 - val_loss: 0.2066\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2089 - val_accuracy: 0.8980 - val_loss: 0.2068\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2007 - val_accuracy: 0.8900 - val_loss: 0.2075\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.1921 - val_accuracy: 0.8927 - val_loss: 0.2058\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2005 - val_accuracy: 0.9027 - val_loss: 0.2015\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2006 - val_accuracy: 0.8920 - val_loss: 0.2084\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.1986 - val_accuracy: 0.8973 - val_loss: 0.2038\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.1881 - val_accuracy: 0.8960 - val_loss: 0.2034\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=1, neurons_per_layer=128, learning_rate=0.01, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.2958 - val_accuracy: 0.8800 - val_loss: 0.2608\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.2511 - val_accuracy: 0.8713 - val_loss: 0.2571\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.2463 - val_accuracy: 0.8853 - val_loss: 0.2344\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2313 - val_accuracy: 0.8993 - val_loss: 0.2192\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2256 - val_accuracy: 0.8980 - val_loss: 0.2165\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8903 - loss: 0.2203 - val_accuracy: 0.9033 - val_loss: 0.2093\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.2195 - val_accuracy: 0.8967 - val_loss: 0.2145\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2121 - val_accuracy: 0.8927 - val_loss: 0.2082\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.2080 - val_accuracy: 0.8920 - val_loss: 0.2108\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.2054 - val_accuracy: 0.8967 - val_loss: 0.2073\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.2069 - val_accuracy: 0.9007 - val_loss: 0.2040\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.1957 - val_accuracy: 0.8953 - val_loss: 0.2036\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.1988 - val_accuracy: 0.9000 - val_loss: 0.2023\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2059 - val_accuracy: 0.8960 - val_loss: 0.2080\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.1976 - val_accuracy: 0.8987 - val_loss: 0.2073\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.2055 - val_accuracy: 0.8953 - val_loss: 0.2016\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.2026 - val_accuracy: 0.8927 - val_loss: 0.2090\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2036 - val_accuracy: 0.8987 - val_loss: 0.2076\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.1953 - val_accuracy: 0.9013 - val_loss: 0.2046\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.001, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7300 - loss: 0.5054 - val_accuracy: 0.8800 - val_loss: 0.2678\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2799 - val_accuracy: 0.8867 - val_loss: 0.2567\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.2699 - val_accuracy: 0.8847 - val_loss: 0.2543\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2556 - val_accuracy: 0.8833 - val_loss: 0.2518\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.2674 - val_accuracy: 0.8820 - val_loss: 0.2511\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.2608 - val_accuracy: 0.8847 - val_loss: 0.2497\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.2496 - val_accuracy: 0.8860 - val_loss: 0.2474\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2462 - val_accuracy: 0.8820 - val_loss: 0.2452\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.2492 - val_accuracy: 0.8853 - val_loss: 0.2420\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2355 - val_accuracy: 0.8833 - val_loss: 0.2394\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.2389 - val_accuracy: 0.8853 - val_loss: 0.2388\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2330 - val_accuracy: 0.8847 - val_loss: 0.2352\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8829 - loss: 0.2372 - val_accuracy: 0.8827 - val_loss: 0.2314\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.2364 - val_accuracy: 0.8873 - val_loss: 0.2275\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.2302 - val_accuracy: 0.8867 - val_loss: 0.2268\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2308 - val_accuracy: 0.8840 - val_loss: 0.2233\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2225 - val_accuracy: 0.8900 - val_loss: 0.2211\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2162 - val_accuracy: 0.8933 - val_loss: 0.2181\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2237 - val_accuracy: 0.8920 - val_loss: 0.2161\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.2155 - val_accuracy: 0.8927 - val_loss: 0.2159\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9023 - loss: 0.2087 - val_accuracy: 0.8967 - val_loss: 0.2126\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.2108 - val_accuracy: 0.8980 - val_loss: 0.2113\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.2084 - val_accuracy: 0.8980 - val_loss: 0.2089\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9042 - loss: 0.2139 - val_accuracy: 0.8980 - val_loss: 0.2077\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8966 - loss: 0.2113 - val_accuracy: 0.8973 - val_loss: 0.2085\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.2061 - val_accuracy: 0.8980 - val_loss: 0.2057\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8926 - loss: 0.2126 - val_accuracy: 0.8980 - val_loss: 0.2052\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2129 - val_accuracy: 0.8960 - val_loss: 0.2056\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.1999 - val_accuracy: 0.8973 - val_loss: 0.2041\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2043 - val_accuracy: 0.9007 - val_loss: 0.2032\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2032 - val_accuracy: 0.8987 - val_loss: 0.2026\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2112 - val_accuracy: 0.8967 - val_loss: 0.2025\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.2020 - val_accuracy: 0.8993 - val_loss: 0.2025\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2042 - val_accuracy: 0.9007 - val_loss: 0.1998\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.2071 - val_accuracy: 0.8973 - val_loss: 0.1999\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.2016 - val_accuracy: 0.8987 - val_loss: 0.2014\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2011 - val_accuracy: 0.8967 - val_loss: 0.2007\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.001, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.5595 - val_accuracy: 0.8767 - val_loss: 0.2683\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.3154 - val_accuracy: 0.8853 - val_loss: 0.2590\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.2857 - val_accuracy: 0.8780 - val_loss: 0.2557\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.2901 - val_accuracy: 0.8860 - val_loss: 0.2536\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2668 - val_accuracy: 0.8833 - val_loss: 0.2537\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.2746 - val_accuracy: 0.8820 - val_loss: 0.2517\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.2693 - val_accuracy: 0.8807 - val_loss: 0.2530\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.2654 - val_accuracy: 0.8820 - val_loss: 0.2512\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.2678 - val_accuracy: 0.8813 - val_loss: 0.2504\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.2622 - val_accuracy: 0.8807 - val_loss: 0.2502\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2591 - val_accuracy: 0.8833 - val_loss: 0.2493\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.2638 - val_accuracy: 0.8827 - val_loss: 0.2471\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.2597 - val_accuracy: 0.8867 - val_loss: 0.2436\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8901 - loss: 0.2476 - val_accuracy: 0.8887 - val_loss: 0.2414\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8888 - loss: 0.2439 - val_accuracy: 0.8860 - val_loss: 0.2403\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2493 - val_accuracy: 0.8893 - val_loss: 0.2373\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.2397 - val_accuracy: 0.8900 - val_loss: 0.2363\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2426 - val_accuracy: 0.8853 - val_loss: 0.2348\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2406 - val_accuracy: 0.8840 - val_loss: 0.2348\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2369 - val_accuracy: 0.8867 - val_loss: 0.2321\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.2342 - val_accuracy: 0.8880 - val_loss: 0.2306\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8962 - loss: 0.2326 - val_accuracy: 0.8920 - val_loss: 0.2294\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.2406 - val_accuracy: 0.8947 - val_loss: 0.2290\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.2347 - val_accuracy: 0.8940 - val_loss: 0.2267\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8950 - loss: 0.2227 - val_accuracy: 0.8913 - val_loss: 0.2274\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.2305 - val_accuracy: 0.8940 - val_loss: 0.2240\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9014 - loss: 0.2205 - val_accuracy: 0.8940 - val_loss: 0.2232\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2227 - val_accuracy: 0.8940 - val_loss: 0.2231\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.2263 - val_accuracy: 0.8953 - val_loss: 0.2177\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2273 - val_accuracy: 0.8920 - val_loss: 0.2186\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.2168 - val_accuracy: 0.8933 - val_loss: 0.2168\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.2229 - val_accuracy: 0.8933 - val_loss: 0.2166\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.2281 - val_accuracy: 0.8967 - val_loss: 0.2134\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2123 - val_accuracy: 0.8947 - val_loss: 0.2143\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.2187 - val_accuracy: 0.8940 - val_loss: 0.2139\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.2155 - val_accuracy: 0.8967 - val_loss: 0.2115\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9006 - loss: 0.2101 - val_accuracy: 0.8973 - val_loss: 0.2095\n",
      "Epoch 38/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.2204 - val_accuracy: 0.8940 - val_loss: 0.2089\n",
      "Epoch 39/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2141 - val_accuracy: 0.8973 - val_loss: 0.2094\n",
      "Epoch 40/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2102 - val_accuracy: 0.8987 - val_loss: 0.2082\n",
      "Epoch 41/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9044 - loss: 0.2060 - val_accuracy: 0.8973 - val_loss: 0.2067\n",
      "Epoch 42/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8954 - loss: 0.2150 - val_accuracy: 0.8967 - val_loss: 0.2079\n",
      "Epoch 43/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.2044 - val_accuracy: 0.8960 - val_loss: 0.2063\n",
      "Epoch 44/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8993 - loss: 0.2091 - val_accuracy: 0.8947 - val_loss: 0.2080\n",
      "Epoch 45/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2039 - val_accuracy: 0.8973 - val_loss: 0.2042\n",
      "Epoch 46/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2034 - val_accuracy: 0.8953 - val_loss: 0.2048\n",
      "Epoch 47/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2033 - val_accuracy: 0.8973 - val_loss: 0.2047\n",
      "Epoch 48/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2067 - val_accuracy: 0.8947 - val_loss: 0.2061\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.001, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.5525 - val_accuracy: 0.8767 - val_loss: 0.2758\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3104 - val_accuracy: 0.8833 - val_loss: 0.2626\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.2697 - val_accuracy: 0.8853 - val_loss: 0.2579\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.2796 - val_accuracy: 0.8840 - val_loss: 0.2560\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.2710 - val_accuracy: 0.8840 - val_loss: 0.2549\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8814 - loss: 0.2639 - val_accuracy: 0.8860 - val_loss: 0.2523\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.2626 - val_accuracy: 0.8860 - val_loss: 0.2524\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2491 - val_accuracy: 0.8840 - val_loss: 0.2496\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.2569 - val_accuracy: 0.8860 - val_loss: 0.2490\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.2491 - val_accuracy: 0.8847 - val_loss: 0.2474\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2400 - val_accuracy: 0.8867 - val_loss: 0.2455\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2486 - val_accuracy: 0.8887 - val_loss: 0.2437\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.2488 - val_accuracy: 0.8860 - val_loss: 0.2438\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2384 - val_accuracy: 0.8840 - val_loss: 0.2420\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.2508 - val_accuracy: 0.8860 - val_loss: 0.2388\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2431 - val_accuracy: 0.8847 - val_loss: 0.2375\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8948 - loss: 0.2292 - val_accuracy: 0.8853 - val_loss: 0.2342\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.2365 - val_accuracy: 0.8893 - val_loss: 0.2330\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2330 - val_accuracy: 0.8947 - val_loss: 0.2313\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2409 - val_accuracy: 0.8867 - val_loss: 0.2306\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9004 - loss: 0.2174 - val_accuracy: 0.8933 - val_loss: 0.2290\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 0.2236 - val_accuracy: 0.8913 - val_loss: 0.2267\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8978 - loss: 0.2254 - val_accuracy: 0.8900 - val_loss: 0.2252\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9042 - loss: 0.2105 - val_accuracy: 0.8920 - val_loss: 0.2235\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.2332 - val_accuracy: 0.8940 - val_loss: 0.2222\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.2251 - val_accuracy: 0.8947 - val_loss: 0.2194\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.2203 - val_accuracy: 0.8933 - val_loss: 0.2185\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.2257 - val_accuracy: 0.8947 - val_loss: 0.2160\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2210 - val_accuracy: 0.8967 - val_loss: 0.2162\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.2152 - val_accuracy: 0.9013 - val_loss: 0.2133\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2036 - val_accuracy: 0.9013 - val_loss: 0.2121\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.2070 - val_accuracy: 0.9007 - val_loss: 0.2117\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2087 - val_accuracy: 0.9027 - val_loss: 0.2094\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2126 - val_accuracy: 0.9033 - val_loss: 0.2074\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2129 - val_accuracy: 0.9027 - val_loss: 0.2069\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2050 - val_accuracy: 0.9000 - val_loss: 0.2061\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.2133 - val_accuracy: 0.9007 - val_loss: 0.2065\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.1991 - val_accuracy: 0.9007 - val_loss: 0.2047\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.1984 - val_accuracy: 0.8993 - val_loss: 0.2040\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.1979 - val_accuracy: 0.8987 - val_loss: 0.2051\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.2021 - val_accuracy: 0.8993 - val_loss: 0.2064\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2092 - val_accuracy: 0.8993 - val_loss: 0.2048\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.001, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6395 - loss: 0.6154 - val_accuracy: 0.8733 - val_loss: 0.2964\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3656 - val_accuracy: 0.8820 - val_loss: 0.2649\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3153 - val_accuracy: 0.8807 - val_loss: 0.2593\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3079 - val_accuracy: 0.8800 - val_loss: 0.2581\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.2966 - val_accuracy: 0.8853 - val_loss: 0.2549\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.2882 - val_accuracy: 0.8840 - val_loss: 0.2540\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.2692 - val_accuracy: 0.8827 - val_loss: 0.2538\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.2736 - val_accuracy: 0.8813 - val_loss: 0.2539\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.2728 - val_accuracy: 0.8820 - val_loss: 0.2526\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2570 - val_accuracy: 0.8840 - val_loss: 0.2515\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.2574 - val_accuracy: 0.8827 - val_loss: 0.2521\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.2596 - val_accuracy: 0.8847 - val_loss: 0.2507\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.2609 - val_accuracy: 0.8847 - val_loss: 0.2491\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.2665 - val_accuracy: 0.8847 - val_loss: 0.2485\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.2615 - val_accuracy: 0.8867 - val_loss: 0.2456\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.2493 - val_accuracy: 0.8840 - val_loss: 0.2455\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.2556 - val_accuracy: 0.8860 - val_loss: 0.2435\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8884 - loss: 0.2485 - val_accuracy: 0.8873 - val_loss: 0.2429\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2474 - val_accuracy: 0.8880 - val_loss: 0.2401\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2490 - val_accuracy: 0.8880 - val_loss: 0.2380\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2380 - val_accuracy: 0.8887 - val_loss: 0.2343\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.2517 - val_accuracy: 0.8880 - val_loss: 0.2341\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2485 - val_accuracy: 0.8887 - val_loss: 0.2342\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2387 - val_accuracy: 0.8913 - val_loss: 0.2298\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2401 - val_accuracy: 0.8960 - val_loss: 0.2276\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.2413 - val_accuracy: 0.8927 - val_loss: 0.2280\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.2431 - val_accuracy: 0.8960 - val_loss: 0.2249\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.2333 - val_accuracy: 0.8940 - val_loss: 0.2218\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8878 - loss: 0.2338 - val_accuracy: 0.8967 - val_loss: 0.2202\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2288 - val_accuracy: 0.8953 - val_loss: 0.2192\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8976 - loss: 0.2212 - val_accuracy: 0.8947 - val_loss: 0.2173\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.2304 - val_accuracy: 0.8960 - val_loss: 0.2170\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2179 - val_accuracy: 0.8913 - val_loss: 0.2183\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8876 - loss: 0.2258 - val_accuracy: 0.8927 - val_loss: 0.2170\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.2142 - val_accuracy: 0.8980 - val_loss: 0.2147\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.2266 - val_accuracy: 0.8960 - val_loss: 0.2149\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.2242 - val_accuracy: 0.8967 - val_loss: 0.2136\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2201 - val_accuracy: 0.8987 - val_loss: 0.2124\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.2141 - val_accuracy: 0.9013 - val_loss: 0.2101\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.2272 - val_accuracy: 0.9013 - val_loss: 0.2104\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.2200 - val_accuracy: 0.9000 - val_loss: 0.2105\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.2198 - val_accuracy: 0.8980 - val_loss: 0.2093\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8957 - loss: 0.2225 - val_accuracy: 0.8993 - val_loss: 0.2074\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.2195 - val_accuracy: 0.9020 - val_loss: 0.2067\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2177 - val_accuracy: 0.8987 - val_loss: 0.2070\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2176 - val_accuracy: 0.8980 - val_loss: 0.2080\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2081 - val_accuracy: 0.9007 - val_loss: 0.2056\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2182 - val_accuracy: 0.9007 - val_loss: 0.2042\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2044 - val_accuracy: 0.9040 - val_loss: 0.2052\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8934 - loss: 0.2134 - val_accuracy: 0.8967 - val_loss: 0.2066\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.01, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.3434 - val_accuracy: 0.8860 - val_loss: 0.2522\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8865 - loss: 0.2582 - val_accuracy: 0.8833 - val_loss: 0.2378\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2389 - val_accuracy: 0.8927 - val_loss: 0.2155\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2351 - val_accuracy: 0.8913 - val_loss: 0.2184\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.2256 - val_accuracy: 0.8960 - val_loss: 0.2133\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2198 - val_accuracy: 0.8960 - val_loss: 0.2181\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2220 - val_accuracy: 0.8980 - val_loss: 0.2082\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.2183 - val_accuracy: 0.9027 - val_loss: 0.2131\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2173 - val_accuracy: 0.9007 - val_loss: 0.2081\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2174 - val_accuracy: 0.8993 - val_loss: 0.2102\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2086 - val_accuracy: 0.8960 - val_loss: 0.2074\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2193 - val_accuracy: 0.8940 - val_loss: 0.2085\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2059 - val_accuracy: 0.8987 - val_loss: 0.2031\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2121 - val_accuracy: 0.9013 - val_loss: 0.2023\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2046 - val_accuracy: 0.8987 - val_loss: 0.2031\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1984 - val_accuracy: 0.8940 - val_loss: 0.2078\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2126 - val_accuracy: 0.8993 - val_loss: 0.2020\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2168 - val_accuracy: 0.8993 - val_loss: 0.2062\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2176 - val_accuracy: 0.9033 - val_loss: 0.2012\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2048 - val_accuracy: 0.8993 - val_loss: 0.2037\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2088 - val_accuracy: 0.9000 - val_loss: 0.1968\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1997 - val_accuracy: 0.9027 - val_loss: 0.2033\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.2084 - val_accuracy: 0.8987 - val_loss: 0.1990\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9017 - loss: 0.2035 - val_accuracy: 0.9060 - val_loss: 0.1974\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.01, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3573 - val_accuracy: 0.8787 - val_loss: 0.2542\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.2820 - val_accuracy: 0.8893 - val_loss: 0.2416\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 0.2618 - val_accuracy: 0.8867 - val_loss: 0.2391\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2443 - val_accuracy: 0.8847 - val_loss: 0.2283\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.2561 - val_accuracy: 0.8827 - val_loss: 0.2262\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.2355 - val_accuracy: 0.8860 - val_loss: 0.2211\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2341 - val_accuracy: 0.8893 - val_loss: 0.2281\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.2498 - val_accuracy: 0.8920 - val_loss: 0.2145\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.2318 - val_accuracy: 0.8993 - val_loss: 0.2109\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2335 - val_accuracy: 0.8880 - val_loss: 0.2151\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.2328 - val_accuracy: 0.8967 - val_loss: 0.2160\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.2335 - val_accuracy: 0.8940 - val_loss: 0.2127\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.01, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.3555 - val_accuracy: 0.8780 - val_loss: 0.2490\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.2542 - val_accuracy: 0.8847 - val_loss: 0.2399\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2405 - val_accuracy: 0.8840 - val_loss: 0.2316\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2273 - val_accuracy: 0.8880 - val_loss: 0.2272\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8814 - loss: 0.2340 - val_accuracy: 0.8980 - val_loss: 0.2138\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2149 - val_accuracy: 0.8967 - val_loss: 0.2099\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2154 - val_accuracy: 0.8920 - val_loss: 0.2166\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.2090 - val_accuracy: 0.9040 - val_loss: 0.2044\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2181 - val_accuracy: 0.8993 - val_loss: 0.2112\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2123 - val_accuracy: 0.9027 - val_loss: 0.2015\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2015 - val_accuracy: 0.9000 - val_loss: 0.2038\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.2104 - val_accuracy: 0.9007 - val_loss: 0.2078\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9023 - loss: 0.2017 - val_accuracy: 0.8967 - val_loss: 0.2053\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=32, learning_rate=0.01, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.3935 - val_accuracy: 0.8787 - val_loss: 0.2566\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.2829 - val_accuracy: 0.8787 - val_loss: 0.2501\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.2627 - val_accuracy: 0.8860 - val_loss: 0.2372\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.2564 - val_accuracy: 0.8780 - val_loss: 0.2328\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.2420 - val_accuracy: 0.8960 - val_loss: 0.2264\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.2355 - val_accuracy: 0.8960 - val_loss: 0.2148\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.2482 - val_accuracy: 0.8927 - val_loss: 0.2196\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.2283 - val_accuracy: 0.8933 - val_loss: 0.2159\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.2300 - val_accuracy: 0.9007 - val_loss: 0.2207\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.001, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.3945 - val_accuracy: 0.8827 - val_loss: 0.2604\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2695 - val_accuracy: 0.8827 - val_loss: 0.2560\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.2588 - val_accuracy: 0.8867 - val_loss: 0.2531\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2526 - val_accuracy: 0.8860 - val_loss: 0.2503\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.2451 - val_accuracy: 0.8833 - val_loss: 0.2466\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.2535 - val_accuracy: 0.8867 - val_loss: 0.2432\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2300 - val_accuracy: 0.8867 - val_loss: 0.2386\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2336 - val_accuracy: 0.8947 - val_loss: 0.2335\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2245 - val_accuracy: 0.8893 - val_loss: 0.2324\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.2151 - val_accuracy: 0.8873 - val_loss: 0.2260\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2175 - val_accuracy: 0.8980 - val_loss: 0.2193\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2176 - val_accuracy: 0.9020 - val_loss: 0.2177\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.2208 - val_accuracy: 0.8980 - val_loss: 0.2150\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2064 - val_accuracy: 0.8993 - val_loss: 0.2123\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2121 - val_accuracy: 0.8973 - val_loss: 0.2123\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.2132 - val_accuracy: 0.8940 - val_loss: 0.2080\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.2013 - val_accuracy: 0.8960 - val_loss: 0.2081\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2032 - val_accuracy: 0.8980 - val_loss: 0.2054\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2008 - val_accuracy: 0.8980 - val_loss: 0.2070\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.2107 - val_accuracy: 0.9013 - val_loss: 0.2038\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2025 - val_accuracy: 0.9007 - val_loss: 0.2028\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.2035 - val_accuracy: 0.9007 - val_loss: 0.2032\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.1964 - val_accuracy: 0.8987 - val_loss: 0.2032\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2042 - val_accuracy: 0.8993 - val_loss: 0.2012\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2091 - val_accuracy: 0.9020 - val_loss: 0.2018\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.1975 - val_accuracy: 0.8953 - val_loss: 0.2038\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.1970 - val_accuracy: 0.9000 - val_loss: 0.2014\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.001, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.4508 - val_accuracy: 0.8787 - val_loss: 0.2615\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.2824 - val_accuracy: 0.8787 - val_loss: 0.2582\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.2550 - val_accuracy: 0.8827 - val_loss: 0.2544\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.2609 - val_accuracy: 0.8873 - val_loss: 0.2527\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.2631 - val_accuracy: 0.8887 - val_loss: 0.2497\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2595 - val_accuracy: 0.8867 - val_loss: 0.2467\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8791 - loss: 0.2569 - val_accuracy: 0.8860 - val_loss: 0.2449\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8790 - loss: 0.2478 - val_accuracy: 0.8840 - val_loss: 0.2433\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8921 - loss: 0.2380 - val_accuracy: 0.8820 - val_loss: 0.2433\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.2475 - val_accuracy: 0.8827 - val_loss: 0.2393\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.2379 - val_accuracy: 0.8873 - val_loss: 0.2369\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2481 - val_accuracy: 0.8853 - val_loss: 0.2339\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.2518 - val_accuracy: 0.8907 - val_loss: 0.2317\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2253 - val_accuracy: 0.8947 - val_loss: 0.2279\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.2301 - val_accuracy: 0.8907 - val_loss: 0.2265\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2310 - val_accuracy: 0.8920 - val_loss: 0.2230\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2308 - val_accuracy: 0.8913 - val_loss: 0.2194\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.2277 - val_accuracy: 0.8967 - val_loss: 0.2168\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.2142 - val_accuracy: 0.8947 - val_loss: 0.2152\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2196 - val_accuracy: 0.8987 - val_loss: 0.2138\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.2188 - val_accuracy: 0.8993 - val_loss: 0.2083\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.2096 - val_accuracy: 0.8973 - val_loss: 0.2099\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2196 - val_accuracy: 0.9027 - val_loss: 0.2080\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2037 - val_accuracy: 0.8993 - val_loss: 0.2087\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.1976 - val_accuracy: 0.8973 - val_loss: 0.2067\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2102 - val_accuracy: 0.8967 - val_loss: 0.2071\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.2074 - val_accuracy: 0.8967 - val_loss: 0.2082\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2046 - val_accuracy: 0.8980 - val_loss: 0.2075\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.001, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.4428 - val_accuracy: 0.8800 - val_loss: 0.2603\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.2813 - val_accuracy: 0.8827 - val_loss: 0.2574\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2581 - val_accuracy: 0.8840 - val_loss: 0.2532\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.2577 - val_accuracy: 0.8873 - val_loss: 0.2511\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.2727 - val_accuracy: 0.8840 - val_loss: 0.2500\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.2638 - val_accuracy: 0.8873 - val_loss: 0.2464\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.2473 - val_accuracy: 0.8853 - val_loss: 0.2429\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2441 - val_accuracy: 0.8887 - val_loss: 0.2398\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2339 - val_accuracy: 0.8893 - val_loss: 0.2372\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.2351 - val_accuracy: 0.8913 - val_loss: 0.2324\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.2253 - val_accuracy: 0.8920 - val_loss: 0.2296\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.2307 - val_accuracy: 0.8913 - val_loss: 0.2286\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2284 - val_accuracy: 0.8920 - val_loss: 0.2227\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2296 - val_accuracy: 0.8960 - val_loss: 0.2188\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.2264 - val_accuracy: 0.8947 - val_loss: 0.2190\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.2147 - val_accuracy: 0.9000 - val_loss: 0.2153\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.2133 - val_accuracy: 0.8973 - val_loss: 0.2152\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2204 - val_accuracy: 0.8980 - val_loss: 0.2124\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2137 - val_accuracy: 0.8993 - val_loss: 0.2101\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2019 - val_accuracy: 0.8987 - val_loss: 0.2101\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2077 - val_accuracy: 0.9000 - val_loss: 0.2087\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.1985 - val_accuracy: 0.9000 - val_loss: 0.2079\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2013 - val_accuracy: 0.8987 - val_loss: 0.2082\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.1996 - val_accuracy: 0.8987 - val_loss: 0.2049\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2094 - val_accuracy: 0.9013 - val_loss: 0.2037\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.1937 - val_accuracy: 0.9007 - val_loss: 0.2023\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2049 - val_accuracy: 0.9000 - val_loss: 0.2040\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2029 - val_accuracy: 0.9020 - val_loss: 0.2029\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1940 - val_accuracy: 0.9013 - val_loss: 0.2025\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.001, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7556 - loss: 0.4744 - val_accuracy: 0.8780 - val_loss: 0.2638\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.2887 - val_accuracy: 0.8853 - val_loss: 0.2574\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.2717 - val_accuracy: 0.8873 - val_loss: 0.2559\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.2738 - val_accuracy: 0.8847 - val_loss: 0.2545\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8773 - loss: 0.2617 - val_accuracy: 0.8840 - val_loss: 0.2537\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.2489 - val_accuracy: 0.8840 - val_loss: 0.2515\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.2627 - val_accuracy: 0.8827 - val_loss: 0.2496\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2478 - val_accuracy: 0.8827 - val_loss: 0.2474\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2551 - val_accuracy: 0.8840 - val_loss: 0.2452\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.2513 - val_accuracy: 0.8813 - val_loss: 0.2447\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2398 - val_accuracy: 0.8873 - val_loss: 0.2412\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.2528 - val_accuracy: 0.8867 - val_loss: 0.2391\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2409 - val_accuracy: 0.8887 - val_loss: 0.2354\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.2499 - val_accuracy: 0.8887 - val_loss: 0.2353\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.2301 - val_accuracy: 0.8873 - val_loss: 0.2324\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2287 - val_accuracy: 0.8947 - val_loss: 0.2285\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2326 - val_accuracy: 0.8880 - val_loss: 0.2275\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.2253 - val_accuracy: 0.8927 - val_loss: 0.2245\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2256 - val_accuracy: 0.8927 - val_loss: 0.2237\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2280 - val_accuracy: 0.8940 - val_loss: 0.2205\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.2188 - val_accuracy: 0.8967 - val_loss: 0.2181\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2181 - val_accuracy: 0.8973 - val_loss: 0.2152\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2160 - val_accuracy: 0.8947 - val_loss: 0.2148\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2181 - val_accuracy: 0.8967 - val_loss: 0.2136\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.2172 - val_accuracy: 0.8980 - val_loss: 0.2109\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.2203 - val_accuracy: 0.8980 - val_loss: 0.2114\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2193 - val_accuracy: 0.8980 - val_loss: 0.2099\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2077 - val_accuracy: 0.8987 - val_loss: 0.2091\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2127 - val_accuracy: 0.8973 - val_loss: 0.2079\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2089 - val_accuracy: 0.8973 - val_loss: 0.2080\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.2065 - val_accuracy: 0.8980 - val_loss: 0.2060\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2084 - val_accuracy: 0.8973 - val_loss: 0.2060\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2106 - val_accuracy: 0.8980 - val_loss: 0.2044\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.1996 - val_accuracy: 0.8993 - val_loss: 0.2030\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.2131 - val_accuracy: 0.8987 - val_loss: 0.2024\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2127 - val_accuracy: 0.8980 - val_loss: 0.2016\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.1992 - val_accuracy: 0.8973 - val_loss: 0.2025\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2077 - val_accuracy: 0.8973 - val_loss: 0.2009\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2012 - val_accuracy: 0.8967 - val_loss: 0.2014\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2042 - val_accuracy: 0.8967 - val_loss: 0.2022\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.1977 - val_accuracy: 0.8953 - val_loss: 0.2016\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.01, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3134 - val_accuracy: 0.8847 - val_loss: 0.2501\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2574 - val_accuracy: 0.8913 - val_loss: 0.2415\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2428 - val_accuracy: 0.8960 - val_loss: 0.2257\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2197 - val_accuracy: 0.8887 - val_loss: 0.2194\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2141 - val_accuracy: 0.9073 - val_loss: 0.2143\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2189 - val_accuracy: 0.9000 - val_loss: 0.2199\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2192 - val_accuracy: 0.9013 - val_loss: 0.2008\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2029 - val_accuracy: 0.8973 - val_loss: 0.2389\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2136 - val_accuracy: 0.9033 - val_loss: 0.2056\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.1990 - val_accuracy: 0.8947 - val_loss: 0.2064\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.01, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8430 - loss: 0.3410 - val_accuracy: 0.8720 - val_loss: 0.2632\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 0.2690 - val_accuracy: 0.8760 - val_loss: 0.2437\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.2656 - val_accuracy: 0.8813 - val_loss: 0.2289\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.2490 - val_accuracy: 0.8907 - val_loss: 0.2244\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2292 - val_accuracy: 0.8913 - val_loss: 0.2194\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2285 - val_accuracy: 0.8880 - val_loss: 0.2250\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8867 - loss: 0.2295 - val_accuracy: 0.8833 - val_loss: 0.2255\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.2363 - val_accuracy: 0.8927 - val_loss: 0.2184\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2240 - val_accuracy: 0.9040 - val_loss: 0.2078\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.2359 - val_accuracy: 0.8947 - val_loss: 0.2083\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2259 - val_accuracy: 0.9013 - val_loss: 0.2130\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2230 - val_accuracy: 0.8907 - val_loss: 0.2244\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.01, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.3325 - val_accuracy: 0.8833 - val_loss: 0.2433\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.2389 - val_accuracy: 0.8860 - val_loss: 0.2295\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2230 - val_accuracy: 0.8980 - val_loss: 0.2273\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.2282 - val_accuracy: 0.8927 - val_loss: 0.2147\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.2047 - val_accuracy: 0.8953 - val_loss: 0.2093\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2220 - val_accuracy: 0.8913 - val_loss: 0.2093\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2068 - val_accuracy: 0.9020 - val_loss: 0.2099\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.2003 - val_accuracy: 0.8960 - val_loss: 0.2030\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2075 - val_accuracy: 0.8987 - val_loss: 0.2061\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2092 - val_accuracy: 0.8927 - val_loss: 0.2049\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.2021 - val_accuracy: 0.8967 - val_loss: 0.2090\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=64, learning_rate=0.01, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.3647 - val_accuracy: 0.8800 - val_loss: 0.2527\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2589 - val_accuracy: 0.8860 - val_loss: 0.2515\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.2532 - val_accuracy: 0.8900 - val_loss: 0.2335\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.2435 - val_accuracy: 0.8880 - val_loss: 0.2307\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.2328 - val_accuracy: 0.8953 - val_loss: 0.2162\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2340 - val_accuracy: 0.8960 - val_loss: 0.2154\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2301 - val_accuracy: 0.8980 - val_loss: 0.2222\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.2221 - val_accuracy: 0.8993 - val_loss: 0.2059\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8886 - loss: 0.2246 - val_accuracy: 0.8967 - val_loss: 0.2095\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2144 - val_accuracy: 0.8967 - val_loss: 0.2126\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.2134 - val_accuracy: 0.8987 - val_loss: 0.2044\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2235 - val_accuracy: 0.8987 - val_loss: 0.2051\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.2182 - val_accuracy: 0.9013 - val_loss: 0.2079\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2204 - val_accuracy: 0.8940 - val_loss: 0.2032\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2256 - val_accuracy: 0.8993 - val_loss: 0.2100\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.2144 - val_accuracy: 0.8960 - val_loss: 0.2067\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2171 - val_accuracy: 0.9033 - val_loss: 0.2052\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.001, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3526 - val_accuracy: 0.8793 - val_loss: 0.2611\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.2672 - val_accuracy: 0.8847 - val_loss: 0.2531\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2479 - val_accuracy: 0.8853 - val_loss: 0.2490\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.2324 - val_accuracy: 0.8880 - val_loss: 0.2397\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.2335 - val_accuracy: 0.8953 - val_loss: 0.2292\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2333 - val_accuracy: 0.8967 - val_loss: 0.2215\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2167 - val_accuracy: 0.8940 - val_loss: 0.2194\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2089 - val_accuracy: 0.8973 - val_loss: 0.2138\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2115 - val_accuracy: 0.8987 - val_loss: 0.2118\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2014 - val_accuracy: 0.8993 - val_loss: 0.2099\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.1922 - val_accuracy: 0.9000 - val_loss: 0.2080\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.1968 - val_accuracy: 0.8987 - val_loss: 0.2046\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.2038 - val_accuracy: 0.9007 - val_loss: 0.2039\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.1926 - val_accuracy: 0.8993 - val_loss: 0.2023\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.1910 - val_accuracy: 0.8967 - val_loss: 0.2063\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.1958 - val_accuracy: 0.8987 - val_loss: 0.2044\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9060 - loss: 0.1940 - val_accuracy: 0.8987 - val_loss: 0.2017\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.1941 - val_accuracy: 0.8980 - val_loss: 0.2018\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.1823 - val_accuracy: 0.9020 - val_loss: 0.2005\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9034 - loss: 0.1928 - val_accuracy: 0.8993 - val_loss: 0.1996\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2025 - val_accuracy: 0.9000 - val_loss: 0.2012\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.1872 - val_accuracy: 0.9007 - val_loss: 0.2015\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.1918 - val_accuracy: 0.8993 - val_loss: 0.1977\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1874 - val_accuracy: 0.8993 - val_loss: 0.1995\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9111 - loss: 0.1830 - val_accuracy: 0.9020 - val_loss: 0.1985\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.1822 - val_accuracy: 0.8953 - val_loss: 0.2035\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.001, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.3857 - val_accuracy: 0.8807 - val_loss: 0.2608\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8799 - loss: 0.2688 - val_accuracy: 0.8820 - val_loss: 0.2549\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8783 - loss: 0.2621 - val_accuracy: 0.8827 - val_loss: 0.2543\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.2660 - val_accuracy: 0.8840 - val_loss: 0.2481\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.2594 - val_accuracy: 0.8833 - val_loss: 0.2468\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.2511 - val_accuracy: 0.8813 - val_loss: 0.2426\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.2381 - val_accuracy: 0.8853 - val_loss: 0.2375\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.2351 - val_accuracy: 0.8873 - val_loss: 0.2320\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2268 - val_accuracy: 0.8927 - val_loss: 0.2254\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.2301 - val_accuracy: 0.8953 - val_loss: 0.2216\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.2196 - val_accuracy: 0.8940 - val_loss: 0.2162\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.2063 - val_accuracy: 0.8947 - val_loss: 0.2127\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2141 - val_accuracy: 0.8980 - val_loss: 0.2097\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2157 - val_accuracy: 0.8987 - val_loss: 0.2065\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2024 - val_accuracy: 0.8993 - val_loss: 0.2047\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2101 - val_accuracy: 0.9020 - val_loss: 0.2045\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2141 - val_accuracy: 0.9027 - val_loss: 0.2009\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2102 - val_accuracy: 0.9033 - val_loss: 0.2024\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2038 - val_accuracy: 0.9040 - val_loss: 0.2015\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.2048 - val_accuracy: 0.8980 - val_loss: 0.2002\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2074 - val_accuracy: 0.9020 - val_loss: 0.1973\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.1939 - val_accuracy: 0.9027 - val_loss: 0.1994\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.1950 - val_accuracy: 0.9053 - val_loss: 0.1982\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.2021 - val_accuracy: 0.8973 - val_loss: 0.1970\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1977 - val_accuracy: 0.9007 - val_loss: 0.1981\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.1896 - val_accuracy: 0.9033 - val_loss: 0.1973\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.1958 - val_accuracy: 0.8993 - val_loss: 0.1970\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.1917 - val_accuracy: 0.8993 - val_loss: 0.1966\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.1953 - val_accuracy: 0.8993 - val_loss: 0.2007\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1916 - val_accuracy: 0.8993 - val_loss: 0.1980\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.1891 - val_accuracy: 0.9013 - val_loss: 0.1993\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.001, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3789 - val_accuracy: 0.8787 - val_loss: 0.2636\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8757 - loss: 0.2657 - val_accuracy: 0.8847 - val_loss: 0.2555\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2509 - val_accuracy: 0.8807 - val_loss: 0.2565\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 0.2548 - val_accuracy: 0.8853 - val_loss: 0.2461\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2384 - val_accuracy: 0.8827 - val_loss: 0.2437\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.2315 - val_accuracy: 0.8867 - val_loss: 0.2375\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2319 - val_accuracy: 0.8927 - val_loss: 0.2286\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.2271 - val_accuracy: 0.8947 - val_loss: 0.2247\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.2207 - val_accuracy: 0.8967 - val_loss: 0.2197\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2116 - val_accuracy: 0.9007 - val_loss: 0.2165\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2140 - val_accuracy: 0.8973 - val_loss: 0.2129\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.2108 - val_accuracy: 0.8947 - val_loss: 0.2140\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2083 - val_accuracy: 0.8960 - val_loss: 0.2104\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.1992 - val_accuracy: 0.8933 - val_loss: 0.2085\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2049 - val_accuracy: 0.8993 - val_loss: 0.2059\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2033 - val_accuracy: 0.8987 - val_loss: 0.2051\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.1981 - val_accuracy: 0.8967 - val_loss: 0.2033\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.1949 - val_accuracy: 0.8987 - val_loss: 0.2054\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.1972 - val_accuracy: 0.8987 - val_loss: 0.2050\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.1894 - val_accuracy: 0.8967 - val_loss: 0.2047\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.001, batch_size=32, dropout=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.3881 - val_accuracy: 0.8833 - val_loss: 0.2573\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.2639 - val_accuracy: 0.8807 - val_loss: 0.2563\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.2713 - val_accuracy: 0.8880 - val_loss: 0.2520\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.2575 - val_accuracy: 0.8847 - val_loss: 0.2487\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2411 - val_accuracy: 0.8873 - val_loss: 0.2466\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2475 - val_accuracy: 0.8873 - val_loss: 0.2432\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.2434 - val_accuracy: 0.8907 - val_loss: 0.2405\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2411 - val_accuracy: 0.8913 - val_loss: 0.2367\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.2356 - val_accuracy: 0.8880 - val_loss: 0.2355\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.2392 - val_accuracy: 0.8933 - val_loss: 0.2297\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.2371 - val_accuracy: 0.8907 - val_loss: 0.2261\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2296 - val_accuracy: 0.8907 - val_loss: 0.2269\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.2197 - val_accuracy: 0.8947 - val_loss: 0.2198\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.2202 - val_accuracy: 0.8953 - val_loss: 0.2188\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.2147 - val_accuracy: 0.8987 - val_loss: 0.2158\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2204 - val_accuracy: 0.8973 - val_loss: 0.2131\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.2111 - val_accuracy: 0.8947 - val_loss: 0.2113\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2003 - val_accuracy: 0.8993 - val_loss: 0.2101\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.2157 - val_accuracy: 0.8993 - val_loss: 0.2096\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9072 - loss: 0.2037 - val_accuracy: 0.9000 - val_loss: 0.2063\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2137 - val_accuracy: 0.8973 - val_loss: 0.2047\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2056 - val_accuracy: 0.9013 - val_loss: 0.2044\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.1997 - val_accuracy: 0.9027 - val_loss: 0.2028\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.1997 - val_accuracy: 0.8993 - val_loss: 0.2054\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.1976 - val_accuracy: 0.9013 - val_loss: 0.2006\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8998 - loss: 0.2029 - val_accuracy: 0.9033 - val_loss: 0.1999\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.2022 - val_accuracy: 0.9007 - val_loss: 0.2022\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.1929 - val_accuracy: 0.9073 - val_loss: 0.1997\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9002 - loss: 0.2057 - val_accuracy: 0.9033 - val_loss: 0.2001\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8972 - loss: 0.2060 - val_accuracy: 0.8987 - val_loss: 0.2000\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9018 - loss: 0.1988 - val_accuracy: 0.8993 - val_loss: 0.1987\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2003 - val_accuracy: 0.9027 - val_loss: 0.2003\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.1945 - val_accuracy: 0.9020 - val_loss: 0.1988\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.1925 - val_accuracy: 0.8960 - val_loss: 0.1996\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.01, batch_size=16, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3131 - val_accuracy: 0.8767 - val_loss: 0.2494\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.2464 - val_accuracy: 0.8893 - val_loss: 0.2361\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2321 - val_accuracy: 0.8967 - val_loss: 0.2236\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2344 - val_accuracy: 0.8973 - val_loss: 0.2079\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2129 - val_accuracy: 0.8993 - val_loss: 0.2068\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2293 - val_accuracy: 0.9033 - val_loss: 0.2106\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.2159 - val_accuracy: 0.8993 - val_loss: 0.2183\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1972 - val_accuracy: 0.8947 - val_loss: 0.2059\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.2223 - val_accuracy: 0.8987 - val_loss: 0.2046\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2179 - val_accuracy: 0.9020 - val_loss: 0.2044\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2031 - val_accuracy: 0.9020 - val_loss: 0.2053\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2140 - val_accuracy: 0.8993 - val_loss: 0.2028\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.2087 - val_accuracy: 0.9007 - val_loss: 0.2165\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.2140 - val_accuracy: 0.8940 - val_loss: 0.2038\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2207 - val_accuracy: 0.9040 - val_loss: 0.2038\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.01, batch_size=16, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3168 - val_accuracy: 0.8653 - val_loss: 0.2745\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.2604 - val_accuracy: 0.8727 - val_loss: 0.2386\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.2557 - val_accuracy: 0.8887 - val_loss: 0.2405\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.2427 - val_accuracy: 0.8933 - val_loss: 0.2231\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.2427 - val_accuracy: 0.8860 - val_loss: 0.2182\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.2428 - val_accuracy: 0.8907 - val_loss: 0.2182\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2332 - val_accuracy: 0.8940 - val_loss: 0.2255\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8886 - loss: 0.2339 - val_accuracy: 0.8967 - val_loss: 0.2118\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2343 - val_accuracy: 0.8847 - val_loss: 0.2292\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.2258 - val_accuracy: 0.9020 - val_loss: 0.2057\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2293 - val_accuracy: 0.8960 - val_loss: 0.2197\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2380 - val_accuracy: 0.8967 - val_loss: 0.2093\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2449 - val_accuracy: 0.8833 - val_loss: 0.2294\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.01, batch_size=32, dropout=0.3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.3061 - val_accuracy: 0.8807 - val_loss: 0.2480\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.2406 - val_accuracy: 0.8647 - val_loss: 0.2556\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.2147 - val_accuracy: 0.9000 - val_loss: 0.2190\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2176 - val_accuracy: 0.9000 - val_loss: 0.2113\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.2230 - val_accuracy: 0.8907 - val_loss: 0.2145\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2132 - val_accuracy: 0.8980 - val_loss: 0.2059\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2009 - val_accuracy: 0.9007 - val_loss: 0.2028\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2112 - val_accuracy: 0.8960 - val_loss: 0.2061\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.2076 - val_accuracy: 0.9027 - val_loss: 0.2036\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.2105 - val_accuracy: 0.8967 - val_loss: 0.2052\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Training model with: hidden_layers=2, neurons_per_layer=128, learning_rate=0.01, batch_size=32, dropout=0.5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8559 - loss: 0.3200 - val_accuracy: 0.8840 - val_loss: 0.2477\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.2585 - val_accuracy: 0.8820 - val_loss: 0.2311\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.2487 - val_accuracy: 0.8933 - val_loss: 0.2251\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2337 - val_accuracy: 0.8953 - val_loss: 0.2174\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2375 - val_accuracy: 0.8967 - val_loss: 0.2145\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2289 - val_accuracy: 0.9027 - val_loss: 0.2150\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2185 - val_accuracy: 0.8973 - val_loss: 0.2125\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.2128 - val_accuracy: 0.9000 - val_loss: 0.2160\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2175 - val_accuracy: 0.9027 - val_loss: 0.2090\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2263 - val_accuracy: 0.8967 - val_loss: 0.2106\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.2177 - val_accuracy: 0.8973 - val_loss: 0.2126\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2164 - val_accuracy: 0.8987 - val_loss: 0.2080\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.2239 - val_accuracy: 0.8933 - val_loss: 0.2043\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2147 - val_accuracy: 0.9047 - val_loss: 0.2025\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2195 - val_accuracy: 0.9020 - val_loss: 0.2032\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.2158 - val_accuracy: 0.8960 - val_loss: 0.2074\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2290 - val_accuracy: 0.8913 - val_loss: 0.2144\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Hyperparameter Tuning Results:\n",
      "    Hidden Layers  Neurons per Layer  Learning Rate  Batch Size  Dropout  \\\n",
      "4               1                 32          0.010          16      0.3   \n",
      "43              2                128          0.001          32      0.5   \n",
      "23              1                128          0.010          32      0.5   \n",
      "8               1                 64          0.001          16      0.3   \n",
      "19              1                128          0.001          32      0.5   \n",
      "28              2                 32          0.010          16      0.3   \n",
      "6               1                 32          0.010          32      0.3   \n",
      "32              2                 64          0.001          16      0.3   \n",
      "25              2                 32          0.001          16      0.5   \n",
      "41              2                128          0.001          16      0.5   \n",
      "40              2                128          0.001          16      0.3   \n",
      "12              1                 64          0.010          16      0.3   \n",
      "22              1                128          0.010          32      0.3   \n",
      "46              2                128          0.010          32      0.3   \n",
      "9               1                 64          0.001          16      0.5   \n",
      "15              1                 64          0.010          32      0.5   \n",
      "17              1                128          0.001          16      0.5   \n",
      "30              2                 32          0.010          32      0.3   \n",
      "16              1                128          0.001          16      0.3   \n",
      "39              2                 64          0.010          32      0.5   \n",
      "24              2                 32          0.001          16      0.3   \n",
      "36              2                 64          0.010          16      0.3   \n",
      "35              2                 64          0.001          32      0.5   \n",
      "13              1                 64          0.010          16      0.5   \n",
      "18              1                128          0.001          32      0.3   \n",
      "1               1                 32          0.001          16      0.5   \n",
      "34              2                 64          0.001          32      0.3   \n",
      "26              2                 32          0.001          32      0.3   \n",
      "33              2                 64          0.001          16      0.5   \n",
      "20              1                128          0.010          16      0.3   \n",
      "5               1                 32          0.010          16      0.5   \n",
      "0               1                 32          0.001          16      0.3   \n",
      "2               1                 32          0.001          32      0.3   \n",
      "21              1                128          0.010          16      0.5   \n",
      "37              2                 64          0.010          16      0.5   \n",
      "29              2                 32          0.010          16      0.5   \n",
      "11              1                 64          0.001          32      0.5   \n",
      "14              1                 64          0.010          32      0.3   \n",
      "27              2                 32          0.001          32      0.5   \n",
      "44              2                128          0.010          16      0.3   \n",
      "38              2                 64          0.010          32      0.3   \n",
      "42              2                128          0.001          32      0.3   \n",
      "45              2                128          0.010          16      0.5   \n",
      "7               1                 32          0.010          32      0.5   \n",
      "47              2                128          0.010          32      0.5   \n",
      "3               1                 32          0.001          32      0.5   \n",
      "31              2                 32          0.010          32      0.5   \n",
      "10              1                 64          0.001          32      0.3   \n",
      "\n",
      "    Validation Loss  Test Accuracy  \n",
      "4          0.202322       0.914000  \n",
      "43         0.198664       0.912667  \n",
      "23         0.201551       0.912667  \n",
      "8          0.203955       0.912667  \n",
      "19         0.204983       0.912667  \n",
      "28         0.196835       0.911333  \n",
      "6          0.199405       0.911333  \n",
      "32         0.201223       0.911333  \n",
      "25         0.204201       0.911333  \n",
      "41         0.196552       0.910667  \n",
      "40         0.197692       0.910667  \n",
      "12         0.197795       0.910667  \n",
      "22         0.201518       0.910667  \n",
      "46         0.202800       0.910667  \n",
      "9          0.204757       0.910667  \n",
      "15         0.199968       0.910000  \n",
      "17         0.206989       0.910000  \n",
      "30         0.201539       0.909333  \n",
      "16         0.201676       0.909333  \n",
      "39         0.203168       0.908667  \n",
      "24         0.199849       0.908000  \n",
      "36         0.200781       0.908000  \n",
      "35         0.200927       0.908000  \n",
      "13         0.204323       0.908000  \n",
      "18         0.208576       0.908000  \n",
      "1          0.210067       0.908000  \n",
      "34         0.202264       0.907333  \n",
      "26         0.204022       0.907333  \n",
      "33         0.206733       0.907333  \n",
      "20         0.201835       0.906667  \n",
      "5          0.207346       0.906667  \n",
      "0          0.207725       0.906667  \n",
      "2          0.212455       0.906667  \n",
      "21         0.202456       0.906000  \n",
      "37         0.207757       0.906000  \n",
      "29         0.210928       0.906000  \n",
      "11         0.211151       0.906000  \n",
      "14         0.203398       0.905333  \n",
      "27         0.204161       0.905333  \n",
      "44         0.202750       0.904667  \n",
      "38         0.202962       0.904667  \n",
      "42         0.203303       0.904667  \n",
      "45         0.205734       0.904667  \n",
      "7          0.209285       0.904667  \n",
      "47         0.202454       0.903333  \n",
      "3          0.223885       0.899333  \n",
      "31         0.214800       0.898000  \n",
      "10         0.255010       0.886000  \n",
      "\n",
      "Best Configuration:\n",
      "Hidden Layers         1.000000\n",
      "Neurons per Layer    32.000000\n",
      "Learning Rate         0.010000\n",
      "Batch Size           16.000000\n",
      "Dropout               0.300000\n",
      "Validation Loss       0.202322\n",
      "Test Accuracy         0.914000\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = diabetes.drop('diabetes', axis=1)\n",
    "y = diabetes['diabetes']\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% train\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% val, 15% test\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# Build the Neural Network\n",
    "# -------------------------------\n",
    "def build_model(hidden_layers, neurons_per_layer, learning_rate, dropout):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add input layer and first hidden layer\n",
    "    model.add(Dense(neurons_per_layer, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    # Add additional hidden layers\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))  # Binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Train the model with Early Stopping\n",
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size, epochs):\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    return history\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Threshold at 0.5\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# -------------------------------\n",
    "# Hyperparameter Grid\n",
    "# -------------------------------\n",
    "hidden_layers_list = [1, 2]                # Number of hidden layers\n",
    "neurons_per_layer_list = [32, 64, 128]    # Neurons per layer\n",
    "learning_rates = [0.001, 0.01]            # Learning rates\n",
    "batch_sizes = [16, 32]                    # Batch sizes\n",
    "dropouts = [0.3, 0.5]                     # Dropout rates\n",
    "epochs = 50                               # Epochs\n",
    "\n",
    "# -------------------------------\n",
    "# Training Loop\n",
    "# -------------------------------\n",
    "results = []\n",
    "\n",
    "for hidden_layers in hidden_layers_list:\n",
    "    for neurons_per_layer in neurons_per_layer_list:\n",
    "        for learning_rate in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                for dropout in dropouts:\n",
    "                    print(f\"\\nTraining model with: hidden_layers={hidden_layers}, neurons_per_layer={neurons_per_layer}, learning_rate={learning_rate}, batch_size={batch_size}, dropout={dropout}\")\n",
    "                    \n",
    "                    # Build and train the model\n",
    "                    model = build_model(hidden_layers, neurons_per_layer, learning_rate, dropout)\n",
    "                    history = train_model(model, X_train, y_train, X_val, y_val, batch_size, epochs)\n",
    "                    \n",
    "                    # Evaluate on test set\n",
    "                    test_accuracy = evaluate_model(model, X_test, y_test)\n",
    "                    validation_loss = min(history.history['val_loss'])\n",
    "                    \n",
    "                    # Store results\n",
    "                    results.append({\n",
    "                        \"Hidden Layers\": hidden_layers,\n",
    "                        \"Neurons per Layer\": neurons_per_layer,\n",
    "                        \"Learning Rate\": learning_rate,\n",
    "                        \"Batch Size\": batch_size,\n",
    "                        \"Dropout\": dropout,\n",
    "                        \"Validation Loss\": validation_loss,\n",
    "                        \"Test Accuracy\": test_accuracy\n",
    "                    })\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by test accuracy (descending) and validation loss (ascending)\n",
    "results_df = results_df.sort_values(by=[\"Test Accuracy\", \"Validation Loss\"], ascending=[False, True])\n",
    "\n",
    "print(\"\\nHyperparameter Tuning Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Display the best configuration\n",
    "best_config = results_df.iloc[0]\n",
    "print(\"\\nBest Configuration:\")\n",
    "print(best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8330 - loss: 0.3549 - val_accuracy: 0.8880 - val_loss: 0.2470\n",
      "Epoch 2/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8850 - loss: 0.2457 - val_accuracy: 0.8840 - val_loss: 0.2342\n",
      "Epoch 3/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8840 - loss: 0.2427 - val_accuracy: 0.8867 - val_loss: 0.2260\n",
      "Epoch 4/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.2238 - val_accuracy: 0.8933 - val_loss: 0.2215\n",
      "Epoch 5/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8894 - loss: 0.2271 - val_accuracy: 0.8900 - val_loss: 0.2207\n",
      "Epoch 6/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8974 - loss: 0.2247 - val_accuracy: 0.8927 - val_loss: 0.2208\n",
      "Epoch 7/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8876 - loss: 0.2257 - val_accuracy: 0.8853 - val_loss: 0.2230\n",
      "Epoch 8/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8885 - loss: 0.2259 - val_accuracy: 0.9000 - val_loss: 0.2045\n",
      "Epoch 9/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8921 - loss: 0.2301 - val_accuracy: 0.9013 - val_loss: 0.2115\n",
      "Epoch 10/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.2213 - val_accuracy: 0.8927 - val_loss: 0.2087\n",
      "Epoch 11/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.2128 - val_accuracy: 0.8920 - val_loss: 0.2214\n",
      "Epoch 12/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8998 - loss: 0.2144 - val_accuracy: 0.8900 - val_loss: 0.2113\n",
      "Epoch 13/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8928 - loss: 0.2143 - val_accuracy: 0.8980 - val_loss: 0.2093\n",
      "Epoch 14/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.2148 - val_accuracy: 0.8980 - val_loss: 0.2061\n",
      "Epoch 15/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8967 - loss: 0.2135 - val_accuracy: 0.8953 - val_loss: 0.2094\n",
      "Epoch 16/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.2109 - val_accuracy: 0.9067 - val_loss: 0.2043\n",
      "Epoch 17/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.2139 - val_accuracy: 0.8980 - val_loss: 0.2070\n",
      "Epoch 18/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8929 - loss: 0.2143 - val_accuracy: 0.8960 - val_loss: 0.2075\n",
      "Epoch 19/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.2213 - val_accuracy: 0.9033 - val_loss: 0.2005\n",
      "Epoch 20/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.2231 - val_accuracy: 0.9000 - val_loss: 0.2032\n",
      "Epoch 21/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8985 - loss: 0.2106 - val_accuracy: 0.9000 - val_loss: 0.2128\n",
      "Epoch 22/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.2079 - val_accuracy: 0.8927 - val_loss: 0.2119\n",
      "Epoch 23/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9007 - loss: 0.2040 - val_accuracy: 0.8953 - val_loss: 0.2076\n",
      "Epoch 24/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2064 - val_accuracy: 0.9020 - val_loss: 0.2075\n",
      "Epoch 25/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.2093 - val_accuracy: 0.8993 - val_loss: 0.2055\n",
      "Epoch 26/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9041 - loss: 0.2013 - val_accuracy: 0.9027 - val_loss: 0.2012\n",
      "Epoch 27/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.1988 - val_accuracy: 0.8967 - val_loss: 0.2072\n",
      "Epoch 28/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9077 - loss: 0.2007 - val_accuracy: 0.8973 - val_loss: 0.2043\n",
      "Epoch 29/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8987 - loss: 0.2137 - val_accuracy: 0.8947 - val_loss: 0.2117\n",
      "Epoch 30/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.2244 - val_accuracy: 0.8973 - val_loss: 0.2094\n",
      "Epoch 31/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9017 - loss: 0.2150 - val_accuracy: 0.9013 - val_loss: 0.2098\n",
      "Epoch 32/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8945 - loss: 0.2264 - val_accuracy: 0.8907 - val_loss: 0.2189\n",
      "Epoch 33/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8951 - loss: 0.2112 - val_accuracy: 0.8953 - val_loss: 0.2124\n",
      "Epoch 34/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8954 - loss: 0.2121 - val_accuracy: 0.8960 - val_loss: 0.2034\n",
      "Epoch 35/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.2163 - val_accuracy: 0.8933 - val_loss: 0.2022\n",
      "Epoch 36/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.2111 - val_accuracy: 0.9013 - val_loss: 0.2049\n",
      "Epoch 37/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9053 - loss: 0.2051 - val_accuracy: 0.8980 - val_loss: 0.2025\n",
      "Epoch 38/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8957 - loss: 0.2696 - val_accuracy: 0.8933 - val_loss: 0.2065\n",
      "Epoch 39/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8972 - loss: 0.2264 - val_accuracy: 0.9027 - val_loss: 0.2097\n",
      "Epoch 40/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9046 - loss: 0.2047 - val_accuracy: 0.9000 - val_loss: 0.2092\n",
      "Epoch 41/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9029 - loss: 0.2113 - val_accuracy: 0.8993 - val_loss: 0.2023\n",
      "Epoch 42/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8938 - loss: 0.2053 - val_accuracy: 0.8993 - val_loss: 0.2080\n",
      "Epoch 43/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8964 - loss: 0.2173 - val_accuracy: 0.8993 - val_loss: 0.2197\n",
      "Epoch 44/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8974 - loss: 0.2145 - val_accuracy: 0.8967 - val_loss: 0.2033\n",
      "Epoch 45/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9026 - loss: 0.2081 - val_accuracy: 0.9013 - val_loss: 0.2074\n",
      "Epoch 46/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.2057 - val_accuracy: 0.9020 - val_loss: 0.1986\n",
      "Epoch 47/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9056 - loss: 0.1944 - val_accuracy: 0.9007 - val_loss: 0.2024\n",
      "Epoch 48/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9012 - loss: 0.2045 - val_accuracy: 0.9033 - val_loss: 0.2040\n",
      "Epoch 49/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8990 - loss: 0.1987 - val_accuracy: 0.9053 - val_loss: 0.1997\n",
      "Epoch 50/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9158 - loss: 0.1854 - val_accuracy: 0.9000 - val_loss: 0.1993\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       730\n",
      "           1       0.89      0.94      0.91       770\n",
      "\n",
      "    accuracy                           0.91      1500\n",
      "   macro avg       0.91      0.91      0.91      1500\n",
      "weighted avg       0.91      0.91      0.91      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "X = diabetes.drop('diabetes', axis=1)\n",
    "y = diabetes['diabetes']\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer + first hidden layer\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),  # Second hidden layer\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),  # Third hidden layer\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=50, verbose=1)\n",
    "\n",
    "# Evaluate the model and generate predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes_model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the model to a file\n",
    "filename = 'diabetes_model.pkl'\n",
    "joblib.dump(model, filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
